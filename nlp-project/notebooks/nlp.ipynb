{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ef5dcb6-71e2-4bd7-8e93-958a4d38fdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/seherova/.pyenv/versions/3.10.12/lib/python3.10/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /Users/seherova/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/seherova/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/seherova/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /Users/seherova/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from nltk) (4.64.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4e08558-42cd-493e-9fb0-7c5a6f9f486e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/seherova/.pyenv/versions/3.10.12/lib/python3.10/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /Users/seherova/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/seherova/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/seherova/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /Users/seherova/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from nltk) (4.64.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1731f846-00e5-48c6-a8e6-4e911d651f89",
   "metadata": {},
   "source": [
    "Normalde !pip install nltk çalıştırdığınızda, sistem PATH’ınızdaki pip’i çağırır; bu ise JupyterLab kernel’inin değil, işletim sisteminizin (örneğin Homebrew’ün) Python’unun pip’idir.\n",
    "\n",
    "Oysa sys.executable size o anda çalışan kernel’in Python yorumlayıcısının tam yolunu verir.\n",
    "\n",
    "Doğru (kernel’in kullandığı) ortamdaki Python’a nltk’yı yüklersiniz. Böylece import nltk hatası ortadan kalktı.\n",
    "\n",
    "sys.executable -m pip install … kullanmak, paketi mutlaka “şu anki kernel’in Python’una” kurar. Bu yöntem, notebook içinde paket yüklerken ortam karışıklığını önlemek için en garantili yoldur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be284228-bb06-414b-9edb-0e2c132097f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/seherova/.pyenv/versions/3.10.12/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/seherova/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/seherova/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/seherova/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/seherova/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/seherova/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca62516a-44bc-416c-967a-2c8f9de0cc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9e6d2cc-ec65-49a1-826d-f6714b74e001",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path(\"/Users/seherova/Desktop/ai-project/news_dataset.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dbf0eeb-021d-4c87-b18c-fbc1c940c946",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "981362cc-e8f8-4f15-b732-e94d26fb13e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Tech You Need to Level Up Your Humanity</td>\n",
       "      <td>Advancements in computing and robotics are cha...</td>\n",
       "      <td>Motion capture technology tracks movements in ...</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How Software Engineers Actually Use AI</td>\n",
       "      <td>We surveyed 730 coders and developers about ho...</td>\n",
       "      <td>Almost every coder we surveyed had strong opin...</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon's AGI Lab Reveals Its First Work: Advan...</td>\n",
       "      <td>Led by a former OpenAI executive, Amazon’s AI ...</td>\n",
       "      <td>Amazon is still seen as a bit of a laggard in ...</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How Microsoft made it through 50 years</td>\n",
       "      <td>In 2005, Microsoftâs leaders were starting t...</td>\n",
       "      <td>How Microsoft made it through 50 years\\r\\nThe ...</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistics giant GXO is going big on humanoid r...</td>\n",
       "      <td>GXO is testing humanoid robots from Agility Ro...</td>\n",
       "      <td>Agility Robotics' Digit robot carries totes in...</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Musk and AI among biggest threats to brand rep...</td>\n",
       "      <td>Appraisal of international public affairs lead...</td>\n",
       "      <td>Associating with the Donald Trump administrati...</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Quebec says no special recruitment measures to...</td>\n",
       "      <td>MONTREAL — Quebec doesn't plan to create any s...</td>\n",
       "      <td>MONTREAL — Quebec doesn't plan to create any s...</td>\n",
       "      <td>medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Boy, 7, dies after woman 'sends poisoned Easte...</td>\n",
       "      <td>The child's mother and 13-year-old sister are ...</td>\n",
       "      <td>Our community members are treated to special o...</td>\n",
       "      <td>medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NDP wealth tax would raise $94.5B, pay for wor...</td>\n",
       "      <td>The party released its platform Saturday, pled...</td>\n",
       "      <td>The New Democratic Party is promising to raise...</td>\n",
       "      <td>medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Israeli strikes on Gaza kill more than 90 peop...</td>\n",
       "      <td>The dead include women and children sheltering...</td>\n",
       "      <td>ISRAELI STRIKES IN Gaza have killed more than ...</td>\n",
       "      <td>medicine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0          The Tech You Need to Level Up Your Humanity   \n",
       "1               How Software Engineers Actually Use AI   \n",
       "2    Amazon's AGI Lab Reveals Its First Work: Advan...   \n",
       "3               How Microsoft made it through 50 years   \n",
       "4    Logistics giant GXO is going big on humanoid r...   \n",
       "..                                                 ...   \n",
       "192  Musk and AI among biggest threats to brand rep...   \n",
       "193  Quebec says no special recruitment measures to...   \n",
       "194  Boy, 7, dies after woman 'sends poisoned Easte...   \n",
       "195  NDP wealth tax would raise $94.5B, pay for wor...   \n",
       "196  Israeli strikes on Gaza kill more than 90 peop...   \n",
       "\n",
       "                                           description  \\\n",
       "0    Advancements in computing and robotics are cha...   \n",
       "1    We surveyed 730 coders and developers about ho...   \n",
       "2    Led by a former OpenAI executive, Amazon’s AI ...   \n",
       "3    In 2005, Microsoftâs leaders were starting t...   \n",
       "4    GXO is testing humanoid robots from Agility Ro...   \n",
       "..                                                 ...   \n",
       "192  Appraisal of international public affairs lead...   \n",
       "193  MONTREAL — Quebec doesn't plan to create any s...   \n",
       "194  The child's mother and 13-year-old sister are ...   \n",
       "195  The party released its platform Saturday, pled...   \n",
       "196  The dead include women and children sheltering...   \n",
       "\n",
       "                                               content   category  \n",
       "0    Motion capture technology tracks movements in ...  technical  \n",
       "1    Almost every coder we surveyed had strong opin...  technical  \n",
       "2    Amazon is still seen as a bit of a laggard in ...  technical  \n",
       "3    How Microsoft made it through 50 years\\r\\nThe ...  technical  \n",
       "4    Agility Robotics' Digit robot carries totes in...  technical  \n",
       "..                                                 ...        ...  \n",
       "192  Associating with the Donald Trump administrati...  technical  \n",
       "193  MONTREAL — Quebec doesn't plan to create any s...   medicine  \n",
       "194  Our community members are treated to special o...   medicine  \n",
       "195  The New Democratic Party is promising to raise...   medicine  \n",
       "196  ISRAELI STRIKES IN Gaza have killed more than ...   medicine  \n",
       "\n",
       "[197 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3bc07ef-073b-46f4-ac10-d588e947d725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['title', 'description', 'content', 'category'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e3817cd-03dd-4ab8-9c6d-ac16e6bdb1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(197, 4)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06a01a52-4d1f-4544-a928-ae04b2b733ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "medicine     103\n",
       "technical     94\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cca414bd-5143-4a38-8edd-5fab4b14f1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Mevcut 'title' başlıklarını al (tekrar eklentileri önlemek için)\n",
    "existing_titles = set(df['title'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c49c52e6-409e-442b-bcd7-c14e00e44dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_articles = [\n",
    "    {\n",
    "        \"title\": \"Breakthrough in Quantum Computing Stability\",\n",
    "        \"description\": \"MIT researchers unveil a novel error-correction method for qubits.\",\n",
    "        \"content\": (\n",
    "            \"In a paper published in Nature, scientists at MIT demonstrated a new \"\n",
    "            \"quantum error-correction protocol that extends qubit coherence times by 50%. \"\n",
    "            \"This advance could accelerate the development of scalable quantum processors.\"\n",
    "        ),\n",
    "        \"category\": \"technical\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"AI-Powered Drone Navigation Breakthrough\",\n",
    "        \"description\": \"A new neural network enables drones to navigate complex environments autonomously.\",\n",
    "        \"content\": (\n",
    "            \"Engineers at Stanford have developed a deep-learning model that processes \"\n",
    "            \"real-time camera feeds to avoid obstacles with 98% accuracy. \"\n",
    "            \"Field tests in dense forests showed significant improvements over existing systems.\"\n",
    "        ),\n",
    "        \"category\": \"technical\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Next-Gen Battery Materials Promise Faster Charging\",\n",
    "        \"description\": \"Scientists identify a new lithium-silicon composite for EV batteries.\",\n",
    "        \"content\": (\n",
    "            \"A team at the University of Texas synthesized a silicon-anode material \"\n",
    "            \"that doubles the energy density and reduces charging time to under 15 minutes. \"\n",
    "            \"Initial automotive tests report stable performance over 1,000 cycles.\"\n",
    "        ),\n",
    "        \"category\": \"technical\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"5G-Integrated IoT Sensors Revolutionize Smart Cities\",\n",
    "        \"description\": \"New tiny sensors leverage 5G for real-time urban monitoring.\",\n",
    "        \"content\": (\n",
    "            \"Researchers at Nokia Bell Labs introduced a family of ultra-low-power IoT \"\n",
    "            \"modules with built-in 5G modems. They demonstrated air-quality and \"\n",
    "            \"traffic monitoring in live city environments with millisecond latency.\"\n",
    "        ),\n",
    "        \"category\": \"technical\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Breakthrough in Photonic Neural Networks\",\n",
    "        \"description\": \"Photonic chips perform AI inference at terahertz speeds.\",\n",
    "        \"content\": (\n",
    "            \"A collaboration between IBM and Caltech produced an optical neural accelerator \"\n",
    "            \"that achieves 1,000× higher throughput than GPU-based inference engines. \"\n",
    "            \"The chip uses silicon photonics to carry out matrix multiplications with light.\"\n",
    "        ),\n",
    "        \"category\": \"technical\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Autonomous Underwater Robots for Deep-Sea Exploration\",\n",
    "        \"description\": \"New AUVs map the ocean floor with unprecedented resolution.\",\n",
    "        \"content\": (\n",
    "            \"OceanX and MIT jointly developed autonomous underwater vehicles equipped \"\n",
    "            \"with advanced sonar and machine-learning navigation. In trials off the \"\n",
    "            \"Galápagos Islands, they produced 3D seafloor maps at 10 cm resolution.\"\n",
    "        ),\n",
    "        \"category\": \"technical\"\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e539ce1b-ca85-4a11-9fa3-9ca0f017237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_add = [art for art in new_articles if art['title'] not in existing_titles]\n",
    "\n",
    "df_new = pd.DataFrame(to_add)\n",
    "df_updated = pd.concat([df, df_new], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4242e1d-8fa0-4792-9197-a36517985624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(to_add))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56f3795e-3008-465d-951f-591756747bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated[\"category\"] = df_updated[\"category\"].str.strip().str.lower()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "321782fd-7a33-4f42-9f82-dd9392defeee",
   "metadata": {},
   "source": [
    "Bu işlemi, kategorilerin doğru şekilde sayılmasını sağlamak amacıyla yaptık. Eğer kategorilerde boşluklar veya farklı harf büyük/küçük kullanımı varsa, bunlar farklı kategoriler olarak kabul edilebilir. Örneğin, \" technical\" (başında boşluk) ile \"technical\" (boşluksuz) iki farklı kategori olarak sayılabilir. Bu nedenle, her iki tarafı da küçük harfe çevirdik ve boşlukları temizledik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5f00225-708b-4f79-8fab-b57d8819a9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "technical    6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_new[\"category\"].value_counts())  # Should show the distribution of categories in new articles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eeb2724d-0372-48b0-8efc-f3d7632cbff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "medicine     103\n",
      "technical    100\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_updated[\"category\"].value_counts())  # To confirm if category counts have updated correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9d03ca8-b02e-4667-9470-22aed74572c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Tech You Need to Level Up Your Humanity</td>\n",
       "      <td>Advancements in computing and robotics are cha...</td>\n",
       "      <td>Motion capture technology tracks movements in ...</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How Software Engineers Actually Use AI</td>\n",
       "      <td>We surveyed 730 coders and developers about ho...</td>\n",
       "      <td>Almost every coder we surveyed had strong opin...</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon's AGI Lab Reveals Its First Work: Advan...</td>\n",
       "      <td>Led by a former OpenAI executive, Amazon’s AI ...</td>\n",
       "      <td>Amazon is still seen as a bit of a laggard in ...</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How Microsoft made it through 50 years</td>\n",
       "      <td>In 2005, Microsoftâs leaders were starting t...</td>\n",
       "      <td>How Microsoft made it through 50 years\\r\\nThe ...</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistics giant GXO is going big on humanoid r...</td>\n",
       "      <td>GXO is testing humanoid robots from Agility Ro...</td>\n",
       "      <td>Agility Robotics' Digit robot carries totes in...</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0        The Tech You Need to Level Up Your Humanity   \n",
       "1             How Software Engineers Actually Use AI   \n",
       "2  Amazon's AGI Lab Reveals Its First Work: Advan...   \n",
       "3             How Microsoft made it through 50 years   \n",
       "4  Logistics giant GXO is going big on humanoid r...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Advancements in computing and robotics are cha...   \n",
       "1  We surveyed 730 coders and developers about ho...   \n",
       "2  Led by a former OpenAI executive, Amazon’s AI ...   \n",
       "3  In 2005, Microsoftâs leaders were starting t...   \n",
       "4  GXO is testing humanoid robots from Agility Ro...   \n",
       "\n",
       "                                             content   category  \n",
       "0  Motion capture technology tracks movements in ...  technical  \n",
       "1  Almost every coder we surveyed had strong opin...  technical  \n",
       "2  Amazon is still seen as a bit of a laggard in ...  technical  \n",
       "3  How Microsoft made it through 50 years\\r\\nThe ...  technical  \n",
       "4  Agility Robotics' Digit robot carries totes in...  technical  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e255fde0-0c1e-4d38-9724-1d0a5443fac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes(include = 'object').columns:\n",
    "    df[col] = df[col].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "486378e0-fa2b-476e-9051-feac10a3d669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the tech you need to level up your humanity</td>\n",
       "      <td>advancements in computing and robotics are cha...</td>\n",
       "      <td>motion capture technology tracks movements in ...</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how software engineers actually use ai</td>\n",
       "      <td>we surveyed 730 coders and developers about ho...</td>\n",
       "      <td>almost every coder we surveyed had strong opin...</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon's agi lab reveals its first work: advan...</td>\n",
       "      <td>led by a former openai executive, amazon’s ai ...</td>\n",
       "      <td>amazon is still seen as a bit of a laggard in ...</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how microsoft made it through 50 years</td>\n",
       "      <td>in 2005, microsoftâs leaders were starting t...</td>\n",
       "      <td>how microsoft made it through 50 years\\r\\nthe ...</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>logistics giant gxo is going big on humanoid r...</td>\n",
       "      <td>gxo is testing humanoid robots from agility ro...</td>\n",
       "      <td>agility robotics' digit robot carries totes in...</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0        the tech you need to level up your humanity   \n",
       "1             how software engineers actually use ai   \n",
       "2  amazon's agi lab reveals its first work: advan...   \n",
       "3             how microsoft made it through 50 years   \n",
       "4  logistics giant gxo is going big on humanoid r...   \n",
       "\n",
       "                                         description  \\\n",
       "0  advancements in computing and robotics are cha...   \n",
       "1  we surveyed 730 coders and developers about ho...   \n",
       "2  led by a former openai executive, amazon’s ai ...   \n",
       "3  in 2005, microsoftâs leaders were starting t...   \n",
       "4  gxo is testing humanoid robots from agility ro...   \n",
       "\n",
       "                                             content   category  \n",
       "0  motion capture technology tracks movements in ...  technical  \n",
       "1  almost every coder we surveyed had strong opin...  technical  \n",
       "2  amazon is still seen as a bit of a laggard in ...  technical  \n",
       "3  how microsoft made it through 50 years\\r\\nthe ...  technical  \n",
       "4  agility robotics' digit robot carries totes in...  technical  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2e495da-34d1-4bb7-a533-cd6baa78e497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the tech you need to level up your humanity</td>\n",
       "      <td>advancements in computing and robotics are cha...</td>\n",
       "      <td>motion capture technology tracks movements in ...</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how software engineers actually use ai</td>\n",
       "      <td>we surveyed 730 coders and developers about ho...</td>\n",
       "      <td>almost every coder we surveyed had strong opin...</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon's agi lab reveals its first work: advan...</td>\n",
       "      <td>led by a former openai executive, amazon’s ai ...</td>\n",
       "      <td>amazon is still seen as a bit of a laggard in ...</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how microsoft made it through 50 years</td>\n",
       "      <td>in 2005, microsoftâs leaders were starting t...</td>\n",
       "      <td>how microsoft made it through 50 years\\r\\nthe ...</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>logistics giant gxo is going big on humanoid r...</td>\n",
       "      <td>gxo is testing humanoid robots from agility ro...</td>\n",
       "      <td>agility robotics' digit robot carries totes in...</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>musk and ai among biggest threats to brand rep...</td>\n",
       "      <td>appraisal of international public affairs lead...</td>\n",
       "      <td>associating with the donald trump administrati...</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>quebec says no special recruitment measures to...</td>\n",
       "      <td>montreal — quebec doesn't plan to create any s...</td>\n",
       "      <td>montreal — quebec doesn't plan to create any s...</td>\n",
       "      <td>medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>boy, 7, dies after woman 'sends poisoned easte...</td>\n",
       "      <td>the child's mother and 13-year-old sister are ...</td>\n",
       "      <td>our community members are treated to special o...</td>\n",
       "      <td>medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>ndp wealth tax would raise $94.5b, pay for wor...</td>\n",
       "      <td>the party released its platform saturday, pled...</td>\n",
       "      <td>the new democratic party is promising to raise...</td>\n",
       "      <td>medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>israeli strikes on gaza kill more than 90 peop...</td>\n",
       "      <td>the dead include women and children sheltering...</td>\n",
       "      <td>israeli strikes in gaza have killed more than ...</td>\n",
       "      <td>medicine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0          the tech you need to level up your humanity   \n",
       "1               how software engineers actually use ai   \n",
       "2    amazon's agi lab reveals its first work: advan...   \n",
       "3               how microsoft made it through 50 years   \n",
       "4    logistics giant gxo is going big on humanoid r...   \n",
       "..                                                 ...   \n",
       "192  musk and ai among biggest threats to brand rep...   \n",
       "193  quebec says no special recruitment measures to...   \n",
       "194  boy, 7, dies after woman 'sends poisoned easte...   \n",
       "195  ndp wealth tax would raise $94.5b, pay for wor...   \n",
       "196  israeli strikes on gaza kill more than 90 peop...   \n",
       "\n",
       "                                           description  \\\n",
       "0    advancements in computing and robotics are cha...   \n",
       "1    we surveyed 730 coders and developers about ho...   \n",
       "2    led by a former openai executive, amazon’s ai ...   \n",
       "3    in 2005, microsoftâs leaders were starting t...   \n",
       "4    gxo is testing humanoid robots from agility ro...   \n",
       "..                                                 ...   \n",
       "192  appraisal of international public affairs lead...   \n",
       "193  montreal — quebec doesn't plan to create any s...   \n",
       "194  the child's mother and 13-year-old sister are ...   \n",
       "195  the party released its platform saturday, pled...   \n",
       "196  the dead include women and children sheltering...   \n",
       "\n",
       "                                               content   category  \n",
       "0    motion capture technology tracks movements in ...  technical  \n",
       "1    almost every coder we surveyed had strong opin...  technical  \n",
       "2    amazon is still seen as a bit of a laggard in ...  technical  \n",
       "3    how microsoft made it through 50 years\\r\\nthe ...  technical  \n",
       "4    agility robotics' digit robot carries totes in...  technical  \n",
       "..                                                 ...        ...  \n",
       "192  associating with the donald trump administrati...  technical  \n",
       "193  montreal — quebec doesn't plan to create any s...   medicine  \n",
       "194  our community members are treated to special o...   medicine  \n",
       "195  the new democratic party is promising to raise...   medicine  \n",
       "196  israeli strikes in gaza have killed more than ...   medicine  \n",
       "\n",
       "[197 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2fd15006-13f3-42c1-a644-459273f844fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b0b5878-4cb5-4114-bcb2-d2cae14f6264",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_pattern = re.compile(r'https?://\\S+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc03e651-afc0-4ade-90aa-f4b07d2e9a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    if isinstance(text, str):\n",
    "        return url_pattern.sub('', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8fec5d56-8e11-487c-a82a-09a4f0fa2976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'description', 'content', 'category'], dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdbc5bb3-80da-40e2-b167-7fb5b26c9e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['title', 'description', 'content', 'category']:\n",
    "    df[col] = df[col].apply(remove_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847c83bf-9883-4481-9bfa-89f5e625ad54",
   "metadata": {},
   "source": [
    "# Metni küçük harfe dönüştür:\n",
    "\n",
    "      *  Doğal dildeki kelimeler, büyük ve küçük harfler arasında ayrım yapılarak farklı token'lar olarak kabul edilir. \n",
    "         Örneğin, \"Apple\" ve \"apple\" iki farklı kelime olarak değerlendirilir.\n",
    "      *  Bu durum, metin verisinin boyutunu artırır ve modelin öğrenme sürecini zorlaştırır.\n",
    "      *  Küçük harfe dönüştürme işlemi, tüm kelimeleri tek bir biçimde temsil ederek bu farkları ortadan kaldırır.\n",
    "      Örnek:\n",
    "      \"Apple\" → \"apple\n",
    "\n",
    "# Stop words kaldırma: \n",
    "\n",
    "      *  Stop words, dilde sıkça kullanılan ancak anlam taşıma açısından düşük öneme sahip kelimelerdir \n",
    "        (örneğin: \"the\", \"is\", \"in\").\n",
    "      *  Bu kelimeler, metin verisinin boyutunu artırır ve modelin öğrenme sürecinde \"gürültü\" (noise) oluşturur.\n",
    "      *  Stop words'lerin kaldırılması, metin verisinin daha özlü ve anlamlı hale gelmesini sağlar.\n",
    "        Örnek:\n",
    "         \"The quick brown fox\" → [\"quick\", \"brown\", \"fox\"]​\n",
    "        \n",
    "      *  Neden Önemlidir:\n",
    "         Modelin, metnin anlamını taşıyan kelimelere odaklanmasını sağlar.\n",
    "         Hesaplama maliyetlerini düşürür ve modelin verimliliğini artırır.\n",
    "\n",
    "# Lemmatizasyon/Stemming: \n",
    "\n",
    "        Stemming algoritmaları,\n",
    "      *  Genellikle kurallara dayalıdır ve kelimenin sonundaki belirli ekleri keser.\n",
    "      *  Örneğin, \"running\" → \"run\", \"happiness\" → \"happi\".\n",
    "      *  Bu süreç, kelimenin morfolojik yapısını dikkate almaz ve bu nedenle \"overstemming\" \n",
    "         (gereksiz yere kelimeleri birleştirme) veya \"understemming\" (benzer kelimeleri ayırma) gibi hatalara yol açabilir.\n",
    "\n",
    "        Avantajları:\n",
    "        Hızlı ve basit bir yöntemdir.\n",
    "        Düşük kaynaklarla çalışabilir.\n",
    "\n",
    "        Dezavantajları:\n",
    "        Anlam kaybına yol açabilir.\n",
    "        Dilbilgisel doğruluk sağlamaz\n",
    "\n",
    "       Lemmatizasyon (Kök Sözcük Bulma)\n",
    "     *  Lemmatizasyon, bir kelimenin doğru kök formunu (lemma) bulma işlemidir.\n",
    "     *  Bu işlem, kelimenin anlamını ve bağlamını dikkate alır\n",
    "\n",
    "\n",
    "        Lemmatizasyon, genellikle aşağıdaki adımları içerir:\n",
    "        \n",
    "      ->  Sözcük Türü Etiketleme (POS Tagging): Kelimenin hangi sözcük türüne (isim, fiil, sıfat vb.) ait olduğunu belirleme.\n",
    "      ->  Morfolojik Çözümleme: Kelimenin yapısını analiz ederek kök formunu bulma.\n",
    "      ->  Sözlük Kullanımı: Kelimenin kök formunu belirlemek için bir sözlük veya veritabanı kullanma.​\n",
    "        \n",
    "        Örnek:\n",
    "        \"better\" (sıfat) → \"good\"\n",
    "        \"running\" (fiil) → \"run\"\n",
    "\n",
    "        Avantajları:\n",
    "        Anlam kaybını en aza indirir.\n",
    "        Dilbilgisel doğruluğu sağlar.\n",
    "        \n",
    "        Dezavantajları:\n",
    "        Daha karmaşık ve zaman alıcıdır.\n",
    "        Daha fazla kaynak ve bilgi gerektirir.\n",
    "\n",
    "\n",
    "# Özel karakterler ve sayılar: \n",
    "        Sayılar, noktalama işaretleri gibi unsurları metinden temizlemek.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c007e3f-5428-4d3e-ba7f-cdfc4d2b464d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run', 'runner', 'run']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "kelimeler = [\"running\", \"runner\", \"runs\"]\n",
    "stemmed_kelimeler = [stemmer.stem(kelime) for kelime in kelimeler]\n",
    "print(stemmed_kelimeler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b59e4d15-f6b1-4977-8de3-bfc889d81ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/seherova/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b6e7131-4e29-4d85-8120-22c155f08fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run', 'better', 'geese']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "words = [\"running\", \"better\", \"geese\"]\n",
    "lemmatized_words = [lemmatizer.lemmatize(word, pos=wordnet.VERB) for word in words]\n",
    "print(lemmatized_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d2e057-5488-4e1e-aed4-4aa19c011179",
   "metadata": {},
   "source": [
    "# 1. Removing non-word and non-whitespace characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9d6225d-7b1f-49c2-897f-716132c1be0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################################for url\n",
    "\n",
    "import re\n",
    "\n",
    "# Define a regex pattern to match URLs\n",
    "url_pattern = re.compile(r'https?://\\S+')\n",
    "\n",
    "def remove_urls(text):\n",
    "    if isinstance(text, str):  # Only apply regex to strings\n",
    "        return url_pattern.sub('', text)\n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ddf5743-74d2-474a-b0e2-79068767b691",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################\n",
    "for col in [\"title\", \"description\",\"content\"]:\n",
    "    df[col] = df[col].apply(remove_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "102d8729-2d7b-4fdf-b9c8-fb4e35d75ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import re\n",
    "#def clear_nonword(text: str) -> str:\n",
    "    # [^\\w\\s] = word ya da whitespace olmayan karakterler\n",
    "#    return re.sub(r'[^\\w\\s]', '', text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca78437b-495f-49ca-b500-77d191a0eb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample = \"Hello, NLP! This is a %& noisy -- text 123.\"\n",
    "#result = clear_nonword(sample)\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ff2b1e7-56cd-4020-b677-10b78b57002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = clear_nonword(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6dd69338-bd8d-4a61-9fa5-c5cac893db33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(to_replace= r'[^\\w\\s]' , value = '', regex = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b46012-e37d-4cd8-a44e-9e93a514564a",
   "metadata": {},
   "source": [
    "# 2. Removing Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f43544fd-1674-4254-bbd2-f05ebf2f8b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#def clean_numbers(num: str) -> str:\n",
    "    # \\d+ = bir veya daha fazlaardışık rakam\n",
    "   # return re.sub(r'\\d+', '', num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "80643abd-f27a-4b28-ba7f-fb7e4a76c85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample2 = \"version 2.0.1 released: 123 errors, 45 warnings\"\n",
    "#result2 = clean_numbers(sample2)\n",
    "#print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "94120424-ba31-49ee-b50c-49a94d9f26e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(to_replace = r'\\d+', value = '', regex= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "156e8f6d-cfb3-4a1c-b8a7-1112350649a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the tech you need to level up your humanity</td>\n",
       "      <td>advancements in computing and robotics are cha...</td>\n",
       "      <td>motion capture technology tracks movements in ...</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how software engineers actually use ai</td>\n",
       "      <td>we surveyed  coders and developers about how a...</td>\n",
       "      <td>almost every coder we surveyed had strong opin...</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazons agi lab reveals its first work advance...</td>\n",
       "      <td>led by a former openai executive amazons ai la...</td>\n",
       "      <td>amazon is still seen as a bit of a laggard in ...</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how microsoft made it through  years</td>\n",
       "      <td>in  microsoftâs leaders were starting to get w...</td>\n",
       "      <td>how microsoft made it through  years\\r\\nthe mo...</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>logistics giant gxo is going big on humanoid r...</td>\n",
       "      <td>gxo is testing humanoid robots from agility ro...</td>\n",
       "      <td>agility robotics digit robot carries totes in ...</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>musk and ai among biggest threats to brand rep...</td>\n",
       "      <td>appraisal of international public affairs lead...</td>\n",
       "      <td>associating with the donald trump administrati...</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>quebec says no special recruitment measures to...</td>\n",
       "      <td>montreal  quebec doesnt plan to create any spe...</td>\n",
       "      <td>montreal  quebec doesnt plan to create any spe...</td>\n",
       "      <td>medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>boy  dies after woman sends poisoned easter eg...</td>\n",
       "      <td>the childs mother and yearold sister are fight...</td>\n",
       "      <td>our community members are treated to special o...</td>\n",
       "      <td>medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>ndp wealth tax would raise b pay for worker ta...</td>\n",
       "      <td>the party released its platform saturday pledg...</td>\n",
       "      <td>the new democratic party is promising to raise...</td>\n",
       "      <td>medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>israeli strikes on gaza kill more than  people...</td>\n",
       "      <td>the dead include women and children sheltering...</td>\n",
       "      <td>israeli strikes in gaza have killed more than ...</td>\n",
       "      <td>medicine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0          the tech you need to level up your humanity   \n",
       "1               how software engineers actually use ai   \n",
       "2    amazons agi lab reveals its first work advance...   \n",
       "3                 how microsoft made it through  years   \n",
       "4    logistics giant gxo is going big on humanoid r...   \n",
       "..                                                 ...   \n",
       "192  musk and ai among biggest threats to brand rep...   \n",
       "193  quebec says no special recruitment measures to...   \n",
       "194  boy  dies after woman sends poisoned easter eg...   \n",
       "195  ndp wealth tax would raise b pay for worker ta...   \n",
       "196  israeli strikes on gaza kill more than  people...   \n",
       "\n",
       "                                           description  \\\n",
       "0    advancements in computing and robotics are cha...   \n",
       "1    we surveyed  coders and developers about how a...   \n",
       "2    led by a former openai executive amazons ai la...   \n",
       "3    in  microsoftâs leaders were starting to get w...   \n",
       "4    gxo is testing humanoid robots from agility ro...   \n",
       "..                                                 ...   \n",
       "192  appraisal of international public affairs lead...   \n",
       "193  montreal  quebec doesnt plan to create any spe...   \n",
       "194  the childs mother and yearold sister are fight...   \n",
       "195  the party released its platform saturday pledg...   \n",
       "196  the dead include women and children sheltering...   \n",
       "\n",
       "                                               content   category  \n",
       "0    motion capture technology tracks movements in ...  technical  \n",
       "1    almost every coder we surveyed had strong opin...  technical  \n",
       "2    amazon is still seen as a bit of a laggard in ...  technical  \n",
       "3    how microsoft made it through  years\\r\\nthe mo...  technical  \n",
       "4    agility robotics digit robot carries totes in ...  technical  \n",
       "..                                                 ...        ...  \n",
       "192  associating with the donald trump administrati...  technical  \n",
       "193  montreal  quebec doesnt plan to create any spe...   medicine  \n",
       "194  our community members are treated to special o...   medicine  \n",
       "195  the new democratic party is promising to raise...   medicine  \n",
       "196  israeli strikes in gaza have killed more than ...   medicine  \n",
       "\n",
       "[197 rows x 4 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168e3243-fb82-4374-904e-e571efc605b7",
   "metadata": {},
   "source": [
    "**Tokenization**, ham metni makinenin anlayabileceği parçalara—genellikle kelimelere veya alt-kelimelere—bölme işlemidir. Bu sayede model, uzun metinleri yönetilebilir “token” dizilerine dönüştürür. \n",
    "\n",
    "Tokenization, bir metni karakter dizisi uzayı $\\Sigma^*$ üzerinden tanımlı bir fonksiyon $\\tau$ ile kelime parçacıklarına $(t_i)$ ayırır; bu işlem, düzenli ifadeler veya deterministik sonlu otomata (DFA) ile $O(n)$ zamanda yapılır.\n",
    "\n",
    "**Stemming** ise her token’ı, eklerinden arındırarak tek bir “kök” formuna indirger; böylece “running”, “runs” ve “runner” gibi varyantlar “run” olarak gruplanır. Aşağıda bu iki adımdaki temel kavramları basit örneklerle ve derinlemesine ama anlaşılır bir dille açıklıyorum.\n",
    "\n",
    "Stemming, her bir token'ı bir kök formuna indirgeyen fonksiyon $\\sigma$ üzerinden yürütülür; Porter algoritması, ek kesme kurallarını uygulayabilmek için \"vowel–consonant\" dizisi sayısını veren bir ölçü $m(w)$ kullanır.\n",
    "\n",
    "## Tokenization için:\n",
    "$$\n",
    "    S = s_1 s_2 \\ldots s_n \\in \\Sigma^*\n",
    "$$\n",
    "    \n",
    "    \n",
    "$$\n",
    "    \\tau : \\Sigma^* \\longrightarrow (\\Sigma^+)^*\n",
    "$$\n",
    "    \n",
    "$$\n",
    "    \\tau(S) = (t_1, t_2, \\ldots, t_m), \\quad \\bigcup_{i=1}^{m} t_i = S\n",
    "$$\n",
    "    \n",
    "Burada her $t_i \\in \\Sigma^+$ bir veya daha fazla karakterden oluşan bir token'dır.\n",
    "    \n",
    " ***En Basit Yöntem: Boşluk Bazlı Bölme:***\n",
    "    \n",
    "```python\n",
    "    text = \"Hello world, how can we split this?\"\n",
    "    tokens = text.split()  # [\"Hello\", \"world,\", \"how\", \"can\", \"we\", \"split\", \"this?\"]\n",
    "    \n",
    "```\n",
    "Artı: Çok hızlı ve her dilde işe yarar.\n",
    "\n",
    "Eksi: Noktalama işaretleri hâlâ kelimede kalır, bazen “böleriz?” yerine “böleriz” bekleriz.\n",
    "Önce noktalama işaretlerini ve sayıları  text'ten silip sonra token'lama işlemi yapılmalı.\n",
    "    \n",
    " **Alt-Kelime (Subword) Tokenization**\n",
    "       \n",
    "Neden? \n",
    "    Özellikle “token” dağarcığı çok büyük olabilir; nadir kelimeler OOV (vocabulary dışı) olabilir.\n",
    "Nasıl?\n",
    "    Byte Pair Encoding (BPE): En sık geçen karakter çiftlerini tekrar tekrar birleştirerek sabit boyutlu bir sözlük oluşturur neptune.ai\n",
    "    Örnek: “low”, “lower”, “newest” → önce “l”, “o”, “w” tekil token, sonra “lo”, “ow” gibi ikili birleştirmeler.\n",
    "    \n",
    "**Hesaplama Karmaşıklığı**\n",
    "    \n",
    "Basit boşluk veya regex tabanlı tokenizasyon, metindeki karakter sayısı $n$ için $O(n)$ zaman karmaşıklığına sahiptir.\n",
    "\n",
    "BPE öğrenme adımı: Tüm karakter çiftlerinin frekansını hesaplamak  için $O(nlog_n)$ civarı olabilir.\n",
    "\n",
    "## Stemming için:\n",
    "\n",
    "Stemming, her bir token $w \\in \\Sigma^*$ için bir kök formu (stem) üreten\n",
    "\n",
    "$$\n",
    "\\sigma : \\Sigma^* \\longrightarrow \\Sigma^*\n",
    "$$\n",
    " \n",
    "fonksiyonudur. Amaç, “running”, “runs”, “runner” gibi farklı biçimlerin hepsini tek bir “run” formunda birleştirmektir \n",
    "\n",
    " Porter, İngilizce kelimelerin eklerinden arındırılarak “stem” (gövde) formuna indirgenmesini sağlayan de facto standart bir algoritmadır.\n",
    " \n",
    "*Ölçü (Measure) 𝑚(𝑤)*\n",
    "\n",
    "Porter’ın ek-süzleme kurallarını koşullamak için tanımladığı, kelimedeki sesli–sessiz bloklarının sayısını gösteren fonksiyondur.\n",
    "- Bir kelimeyi $C$ (bir veya daha fazla sessiz) ve $V$ (bir veya daha fazla sesli) bloklarının bir dizisi olarak düşünürüz.\n",
    "- Ölçü,\n",
    "\n",
    "$$\n",
    "m(w) = |\\{VC \\text{ blokları in } w\\}| - 1\n",
    "$$\n",
    "\n",
    "olarak tanımlanır.  \n",
    "Örneğin \"trouble\" kelimesi \"troub|le\" şeklinde iki blok içerdiği için $m = 1$.\n",
    "\n",
    "Örnek Uygulama\n",
    "“running” → Step 1b: “ing” çıkar → “runn” → çift “nn” → “run”\n",
    "\n",
    "“happily” → Step 2: “ily”→“i” → “happi”\n",
    "\n",
    "“university” → Step 1a: “s” yok, sonraki adımlarda “ity”→“” vs. sonuç “univers” (bir miktar overstemming)\n",
    "\n",
    "**Hesaplama Karmaşıklığı**\n",
    "Her token boyu n ve kural sayısı sabit k iken, Porter stemming tek kelime için 𝑂(𝑛) zaman alır. Tüm metin boyu 𝑁 ise toplamda 𝑂(𝑁) karmaşıklığına ulaşır.\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3ada25-ae23-4f0b-91df-d1e87a83bc0f",
   "metadata": {},
   "source": [
    "# Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "308944ee-65a5-4d1c-93a1-543f6f7c46d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/seherova/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt') # TCümleleri ve kelimeleri doğru bölmek için tüm kuralları ve kodu getirir.\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8bcb6082-8d25-4967-ae4e-2b313710d351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/seherova/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab') # punkt_tab klasörü eksik (M1-M2 çip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "831c9453-3b96-4063-914c-9190271bb8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "df['title_tokens'] = df['title'].apply(lambda x: word_tokenize(x) if isinstance(x, str) else x)\n",
    "df['description_tokens'] = df['description'].apply(lambda x: word_tokenize(x) if isinstance(x, str) else x)\n",
    "df['content_tokens'] = df['content'].apply(lambda x: word_tokenize(x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4654409c-a665-4148-a4ac-671c59413771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "      <th>title_tokens</th>\n",
       "      <th>description_tokens</th>\n",
       "      <th>content_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the tech you need to level up your humanity</td>\n",
       "      <td>advancements in computing and robotics are cha...</td>\n",
       "      <td>motion capture technology tracks movements in ...</td>\n",
       "      <td>technical</td>\n",
       "      <td>[the, tech, you, need, to, level, up, your, hu...</td>\n",
       "      <td>[advancements, in, computing, and, robotics, a...</td>\n",
       "      <td>[motion, capture, technology, tracks, movement...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how software engineers actually use ai</td>\n",
       "      <td>we surveyed  coders and developers about how a...</td>\n",
       "      <td>almost every coder we surveyed had strong opin...</td>\n",
       "      <td>technical</td>\n",
       "      <td>[how, software, engineers, actually, use, ai]</td>\n",
       "      <td>[we, surveyed, coders, and, developers, about,...</td>\n",
       "      <td>[almost, every, coder, we, surveyed, had, stro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazons agi lab reveals its first work advance...</td>\n",
       "      <td>led by a former openai executive amazons ai la...</td>\n",
       "      <td>amazon is still seen as a bit of a laggard in ...</td>\n",
       "      <td>technical</td>\n",
       "      <td>[amazons, agi, lab, reveals, its, first, work,...</td>\n",
       "      <td>[led, by, a, former, openai, executive, amazon...</td>\n",
       "      <td>[amazon, is, still, seen, as, a, bit, of, a, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how microsoft made it through  years</td>\n",
       "      <td>in  microsoftâs leaders were starting to get w...</td>\n",
       "      <td>how microsoft made it through  years\\r\\nthe mo...</td>\n",
       "      <td>technical</td>\n",
       "      <td>[how, microsoft, made, it, through, years]</td>\n",
       "      <td>[in, microsoftâs, leaders, were, starting, to,...</td>\n",
       "      <td>[how, microsoft, made, it, through, years, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>logistics giant gxo is going big on humanoid r...</td>\n",
       "      <td>gxo is testing humanoid robots from agility ro...</td>\n",
       "      <td>agility robotics digit robot carries totes in ...</td>\n",
       "      <td>technical</td>\n",
       "      <td>[logistics, giant, gxo, is, going, big, on, hu...</td>\n",
       "      <td>[gxo, is, testing, humanoid, robots, from, agi...</td>\n",
       "      <td>[agility, robotics, digit, robot, carries, tot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>musk and ai among biggest threats to brand rep...</td>\n",
       "      <td>appraisal of international public affairs lead...</td>\n",
       "      <td>associating with the donald trump administrati...</td>\n",
       "      <td>technical</td>\n",
       "      <td>[musk, and, ai, among, biggest, threats, to, b...</td>\n",
       "      <td>[appraisal, of, international, public, affairs...</td>\n",
       "      <td>[associating, with, the, donald, trump, admini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>quebec says no special recruitment measures to...</td>\n",
       "      <td>montreal  quebec doesnt plan to create any spe...</td>\n",
       "      <td>montreal  quebec doesnt plan to create any spe...</td>\n",
       "      <td>medicine</td>\n",
       "      <td>[quebec, says, no, special, recruitment, measu...</td>\n",
       "      <td>[montreal, quebec, doesnt, plan, to, create, a...</td>\n",
       "      <td>[montreal, quebec, doesnt, plan, to, create, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>boy  dies after woman sends poisoned easter eg...</td>\n",
       "      <td>the childs mother and yearold sister are fight...</td>\n",
       "      <td>our community members are treated to special o...</td>\n",
       "      <td>medicine</td>\n",
       "      <td>[boy, dies, after, woman, sends, poisoned, eas...</td>\n",
       "      <td>[the, childs, mother, and, yearold, sister, ar...</td>\n",
       "      <td>[our, community, members, are, treated, to, sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>ndp wealth tax would raise b pay for worker ta...</td>\n",
       "      <td>the party released its platform saturday pledg...</td>\n",
       "      <td>the new democratic party is promising to raise...</td>\n",
       "      <td>medicine</td>\n",
       "      <td>[ndp, wealth, tax, would, raise, b, pay, for, ...</td>\n",
       "      <td>[the, party, released, its, platform, saturday...</td>\n",
       "      <td>[the, new, democratic, party, is, promising, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>israeli strikes on gaza kill more than  people...</td>\n",
       "      <td>the dead include women and children sheltering...</td>\n",
       "      <td>israeli strikes in gaza have killed more than ...</td>\n",
       "      <td>medicine</td>\n",
       "      <td>[israeli, strikes, on, gaza, kill, more, than,...</td>\n",
       "      <td>[the, dead, include, women, and, children, she...</td>\n",
       "      <td>[israeli, strikes, in, gaza, have, killed, mor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0          the tech you need to level up your humanity   \n",
       "1               how software engineers actually use ai   \n",
       "2    amazons agi lab reveals its first work advance...   \n",
       "3                 how microsoft made it through  years   \n",
       "4    logistics giant gxo is going big on humanoid r...   \n",
       "..                                                 ...   \n",
       "192  musk and ai among biggest threats to brand rep...   \n",
       "193  quebec says no special recruitment measures to...   \n",
       "194  boy  dies after woman sends poisoned easter eg...   \n",
       "195  ndp wealth tax would raise b pay for worker ta...   \n",
       "196  israeli strikes on gaza kill more than  people...   \n",
       "\n",
       "                                           description  \\\n",
       "0    advancements in computing and robotics are cha...   \n",
       "1    we surveyed  coders and developers about how a...   \n",
       "2    led by a former openai executive amazons ai la...   \n",
       "3    in  microsoftâs leaders were starting to get w...   \n",
       "4    gxo is testing humanoid robots from agility ro...   \n",
       "..                                                 ...   \n",
       "192  appraisal of international public affairs lead...   \n",
       "193  montreal  quebec doesnt plan to create any spe...   \n",
       "194  the childs mother and yearold sister are fight...   \n",
       "195  the party released its platform saturday pledg...   \n",
       "196  the dead include women and children sheltering...   \n",
       "\n",
       "                                               content   category  \\\n",
       "0    motion capture technology tracks movements in ...  technical   \n",
       "1    almost every coder we surveyed had strong opin...  technical   \n",
       "2    amazon is still seen as a bit of a laggard in ...  technical   \n",
       "3    how microsoft made it through  years\\r\\nthe mo...  technical   \n",
       "4    agility robotics digit robot carries totes in ...  technical   \n",
       "..                                                 ...        ...   \n",
       "192  associating with the donald trump administrati...  technical   \n",
       "193  montreal  quebec doesnt plan to create any spe...   medicine   \n",
       "194  our community members are treated to special o...   medicine   \n",
       "195  the new democratic party is promising to raise...   medicine   \n",
       "196  israeli strikes in gaza have killed more than ...   medicine   \n",
       "\n",
       "                                          title_tokens  \\\n",
       "0    [the, tech, you, need, to, level, up, your, hu...   \n",
       "1        [how, software, engineers, actually, use, ai]   \n",
       "2    [amazons, agi, lab, reveals, its, first, work,...   \n",
       "3           [how, microsoft, made, it, through, years]   \n",
       "4    [logistics, giant, gxo, is, going, big, on, hu...   \n",
       "..                                                 ...   \n",
       "192  [musk, and, ai, among, biggest, threats, to, b...   \n",
       "193  [quebec, says, no, special, recruitment, measu...   \n",
       "194  [boy, dies, after, woman, sends, poisoned, eas...   \n",
       "195  [ndp, wealth, tax, would, raise, b, pay, for, ...   \n",
       "196  [israeli, strikes, on, gaza, kill, more, than,...   \n",
       "\n",
       "                                    description_tokens  \\\n",
       "0    [advancements, in, computing, and, robotics, a...   \n",
       "1    [we, surveyed, coders, and, developers, about,...   \n",
       "2    [led, by, a, former, openai, executive, amazon...   \n",
       "3    [in, microsoftâs, leaders, were, starting, to,...   \n",
       "4    [gxo, is, testing, humanoid, robots, from, agi...   \n",
       "..                                                 ...   \n",
       "192  [appraisal, of, international, public, affairs...   \n",
       "193  [montreal, quebec, doesnt, plan, to, create, a...   \n",
       "194  [the, childs, mother, and, yearold, sister, ar...   \n",
       "195  [the, party, released, its, platform, saturday...   \n",
       "196  [the, dead, include, women, and, children, she...   \n",
       "\n",
       "                                        content_tokens  \n",
       "0    [motion, capture, technology, tracks, movement...  \n",
       "1    [almost, every, coder, we, surveyed, had, stro...  \n",
       "2    [amazon, is, still, seen, as, a, bit, of, a, l...  \n",
       "3    [how, microsoft, made, it, through, years, the...  \n",
       "4    [agility, robotics, digit, robot, carries, tot...  \n",
       "..                                                 ...  \n",
       "192  [associating, with, the, donald, trump, admini...  \n",
       "193  [montreal, quebec, doesnt, plan, to, create, a...  \n",
       "194  [our, community, members, are, treated, to, sp...  \n",
       "195  [the, new, democratic, party, is, promising, t...  \n",
       "196  [israeli, strikes, in, gaza, have, killed, mor...  \n",
       "\n",
       "[197 rows x 7 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b4cd71-3d7a-4bdf-92ee-2c364ccbe747",
   "metadata": {},
   "source": [
    "# Stopword Removal\n",
    "\n",
    "\n",
    "Stopword'ler, bir dilde sıkça kullanılan ancak metnin anlamına katkısı sınırlı olan kelimelerdir. Türkçede \"ve\", \"bir\", \"ile\", \"bu\" İngilizce'de ise \"of, the, by\" gibi kelimeler bu kategoriye girer. Bu kelimeler, cümle yapısını oluşturmak için gereklidir ancak metin analizi sırasında genellikle bilgi taşımazlar.\n",
    "\n",
    "📊 Neden Stopword'ler Çıkarılır?\n",
    "Stopword'lerin çıkarılması, metin işleme ve doğal dil işleme (NLP) süreçlerinde önemli bir adımdır. Bu işlem, aşağıdaki nedenlerle gerçekleştirilir:\n",
    "\n",
    "Veri Azaltma: Stopword'ler, metnin büyük bir kısmını oluşturabilir. Bunları kaldırmak, veri boyutunu azaltır ve işlemeyi hızlandırır.\n",
    "\n",
    "Gürültü Azaltma: Bu kelimeler, metindeki önemli sinyalleri gizleyebilir. Kaldırıldıklarında, verinin anlamlı kısımları daha belirgin hale gelir.\n",
    "\n",
    "Model Performansı: Makine öğrenimi modelleri, anlamlı kelimelere odaklandığında daha iyi performans gösterir. Stopword'leri kaldırmak, bu odaklanmayı sağlar.\n",
    "\n",
    "1. Kelime Sıklığı ve Zipf Yasası\n",
    "Zipf Yasası, bir dildeki kelimelerin sıklığının, sıralarına ters orantılı olduğunu belirtir. Yani, en sık kullanılan kelimeler (genellikle stopword'ler) metnin büyük bir kısmını oluşturur ancak bilgi taşıma kapasitesi düşüktür.\n",
    "\n",
    "2. TF-IDF (Term Frequency-Inverse Document Frequency)\n",
    "TF-IDF, bir kelimenin bir belgede ne kadar önemli olduğunu ölçen bir metriktir. Stopword'ler, genellikle birçok belgede yüksek sıklıkta bulunduğundan, IDF değerleri düşük olur ve bu da onların öneminin az olduğunu gösterir.\n",
    "\n",
    "\n",
    "Stopword'leri çıkarmak için çeşitli araçlar ve kütüphaneler kullanılabilir:​\n",
    "\n",
    "NLTK (Natural Language Toolkit): Python'da yaygın olarak kullanılan bir NLP kütüphanesidir. İçerisinde çeşitli diller için stopword listeleri barındırır.​\n",
    "\n",
    "SpaCy: Hızlı ve verimli bir NLP kütüphanesidir. Stopword'leri tanımlamak ve çıkarmak için kullanılabilir.​\n",
    "\n",
    "Gensim: Özellikle konu modelleme ve belge  benzerliği analizlerinde kullanılan bir kütüphanedir. Stopword çıkarma işlemleri için de işlevseldir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "13b49959-25e4-41ef-ab45-d4455e163a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/seherova/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f9b746c-742b-4213-83b9-9f038901288e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['title_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e326dd03-acd9-4629-8b1b-ff1277897e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokens):\n",
    "    return [word for word in tokens if word.lower() not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "76e44c9d-7b4d-4264-8ffe-f5480be48d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['content_tokens','description_tokens','title_tokens']:\n",
    "    df[col] = df[col].apply(lambda x :remove_stopwords(x) if isinstance(x, list) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d09cc650-1272-40ad-a6c0-4b3b1459d881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "      <th>title_tokens</th>\n",
       "      <th>description_tokens</th>\n",
       "      <th>content_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the tech you need to level up your humanity</td>\n",
       "      <td>advancements in computing and robotics are cha...</td>\n",
       "      <td>motion capture technology tracks movements in ...</td>\n",
       "      <td>technical</td>\n",
       "      <td>[tech, need, level, humanity]</td>\n",
       "      <td>[advancements, computing, robotics, changing, ...</td>\n",
       "      <td>[motion, capture, technology, tracks, movement...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how software engineers actually use ai</td>\n",
       "      <td>we surveyed  coders and developers about how a...</td>\n",
       "      <td>almost every coder we surveyed had strong opin...</td>\n",
       "      <td>technical</td>\n",
       "      <td>[software, engineers, actually, use, ai]</td>\n",
       "      <td>[surveyed, coders, developers, often, use, ai,...</td>\n",
       "      <td>[almost, every, coder, surveyed, strong, opini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazons agi lab reveals its first work advance...</td>\n",
       "      <td>led by a former openai executive amazons ai la...</td>\n",
       "      <td>amazon is still seen as a bit of a laggard in ...</td>\n",
       "      <td>technical</td>\n",
       "      <td>[amazons, agi, lab, reveals, first, work, adva...</td>\n",
       "      <td>[led, former, openai, executive, amazons, ai, ...</td>\n",
       "      <td>[amazon, still, seen, bit, laggard, race, deve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how microsoft made it through  years</td>\n",
       "      <td>in  microsoftâs leaders were starting to get w...</td>\n",
       "      <td>how microsoft made it through  years\\r\\nthe mo...</td>\n",
       "      <td>technical</td>\n",
       "      <td>[microsoft, made, years]</td>\n",
       "      <td>[microsoftâs, leaders, starting, get, worried,...</td>\n",
       "      <td>[microsoft, made, years, model, built, bill, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>logistics giant gxo is going big on humanoid r...</td>\n",
       "      <td>gxo is testing humanoid robots from agility ro...</td>\n",
       "      <td>agility robotics digit robot carries totes in ...</td>\n",
       "      <td>technical</td>\n",
       "      <td>[logistics, giant, gxo, going, big, humanoid, ...</td>\n",
       "      <td>[gxo, testing, humanoid, robots, agility, robo...</td>\n",
       "      <td>[agility, robotics, digit, robot, carries, tot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>musk and ai among biggest threats to brand rep...</td>\n",
       "      <td>appraisal of international public affairs lead...</td>\n",
       "      <td>associating with the donald trump administrati...</td>\n",
       "      <td>technical</td>\n",
       "      <td>[musk, ai, among, biggest, threats, brand, rep...</td>\n",
       "      <td>[appraisal, international, public, affairs, le...</td>\n",
       "      <td>[associating, donald, trump, administrations, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>quebec says no special recruitment measures to...</td>\n",
       "      <td>montreal  quebec doesnt plan to create any spe...</td>\n",
       "      <td>montreal  quebec doesnt plan to create any spe...</td>\n",
       "      <td>medicine</td>\n",
       "      <td>[quebec, says, special, recruitment, measures,...</td>\n",
       "      <td>[montreal, quebec, doesnt, plan, create, speci...</td>\n",
       "      <td>[montreal, quebec, doesnt, plan, create, speci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>boy  dies after woman sends poisoned easter eg...</td>\n",
       "      <td>the childs mother and yearold sister are fight...</td>\n",
       "      <td>our community members are treated to special o...</td>\n",
       "      <td>medicine</td>\n",
       "      <td>[boy, dies, woman, sends, poisoned, easter, eg...</td>\n",
       "      <td>[childs, mother, yearold, sister, fighting, li...</td>\n",
       "      <td>[community, members, treated, special, offers,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>ndp wealth tax would raise b pay for worker ta...</td>\n",
       "      <td>the party released its platform saturday pledg...</td>\n",
       "      <td>the new democratic party is promising to raise...</td>\n",
       "      <td>medicine</td>\n",
       "      <td>[ndp, wealth, tax, would, raise, b, pay, worke...</td>\n",
       "      <td>[party, released, platform, saturday, pledging...</td>\n",
       "      <td>[new, democratic, party, promising, raise, bil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>israeli strikes on gaza kill more than  people...</td>\n",
       "      <td>the dead include women and children sheltering...</td>\n",
       "      <td>israeli strikes in gaza have killed more than ...</td>\n",
       "      <td>medicine</td>\n",
       "      <td>[israeli, strikes, gaza, kill, people, hours, ...</td>\n",
       "      <td>[dead, include, women, children, sheltering, d...</td>\n",
       "      <td>[israeli, strikes, gaza, killed, people, past,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0          the tech you need to level up your humanity   \n",
       "1               how software engineers actually use ai   \n",
       "2    amazons agi lab reveals its first work advance...   \n",
       "3                 how microsoft made it through  years   \n",
       "4    logistics giant gxo is going big on humanoid r...   \n",
       "..                                                 ...   \n",
       "192  musk and ai among biggest threats to brand rep...   \n",
       "193  quebec says no special recruitment measures to...   \n",
       "194  boy  dies after woman sends poisoned easter eg...   \n",
       "195  ndp wealth tax would raise b pay for worker ta...   \n",
       "196  israeli strikes on gaza kill more than  people...   \n",
       "\n",
       "                                           description  \\\n",
       "0    advancements in computing and robotics are cha...   \n",
       "1    we surveyed  coders and developers about how a...   \n",
       "2    led by a former openai executive amazons ai la...   \n",
       "3    in  microsoftâs leaders were starting to get w...   \n",
       "4    gxo is testing humanoid robots from agility ro...   \n",
       "..                                                 ...   \n",
       "192  appraisal of international public affairs lead...   \n",
       "193  montreal  quebec doesnt plan to create any spe...   \n",
       "194  the childs mother and yearold sister are fight...   \n",
       "195  the party released its platform saturday pledg...   \n",
       "196  the dead include women and children sheltering...   \n",
       "\n",
       "                                               content   category  \\\n",
       "0    motion capture technology tracks movements in ...  technical   \n",
       "1    almost every coder we surveyed had strong opin...  technical   \n",
       "2    amazon is still seen as a bit of a laggard in ...  technical   \n",
       "3    how microsoft made it through  years\\r\\nthe mo...  technical   \n",
       "4    agility robotics digit robot carries totes in ...  technical   \n",
       "..                                                 ...        ...   \n",
       "192  associating with the donald trump administrati...  technical   \n",
       "193  montreal  quebec doesnt plan to create any spe...   medicine   \n",
       "194  our community members are treated to special o...   medicine   \n",
       "195  the new democratic party is promising to raise...   medicine   \n",
       "196  israeli strikes in gaza have killed more than ...   medicine   \n",
       "\n",
       "                                          title_tokens  \\\n",
       "0                        [tech, need, level, humanity]   \n",
       "1             [software, engineers, actually, use, ai]   \n",
       "2    [amazons, agi, lab, reveals, first, work, adva...   \n",
       "3                             [microsoft, made, years]   \n",
       "4    [logistics, giant, gxo, going, big, humanoid, ...   \n",
       "..                                                 ...   \n",
       "192  [musk, ai, among, biggest, threats, brand, rep...   \n",
       "193  [quebec, says, special, recruitment, measures,...   \n",
       "194  [boy, dies, woman, sends, poisoned, easter, eg...   \n",
       "195  [ndp, wealth, tax, would, raise, b, pay, worke...   \n",
       "196  [israeli, strikes, gaza, kill, people, hours, ...   \n",
       "\n",
       "                                    description_tokens  \\\n",
       "0    [advancements, computing, robotics, changing, ...   \n",
       "1    [surveyed, coders, developers, often, use, ai,...   \n",
       "2    [led, former, openai, executive, amazons, ai, ...   \n",
       "3    [microsoftâs, leaders, starting, get, worried,...   \n",
       "4    [gxo, testing, humanoid, robots, agility, robo...   \n",
       "..                                                 ...   \n",
       "192  [appraisal, international, public, affairs, le...   \n",
       "193  [montreal, quebec, doesnt, plan, create, speci...   \n",
       "194  [childs, mother, yearold, sister, fighting, li...   \n",
       "195  [party, released, platform, saturday, pledging...   \n",
       "196  [dead, include, women, children, sheltering, d...   \n",
       "\n",
       "                                        content_tokens  \n",
       "0    [motion, capture, technology, tracks, movement...  \n",
       "1    [almost, every, coder, surveyed, strong, opini...  \n",
       "2    [amazon, still, seen, bit, laggard, race, deve...  \n",
       "3    [microsoft, made, years, model, built, bill, g...  \n",
       "4    [agility, robotics, digit, robot, carries, tot...  \n",
       "..                                                 ...  \n",
       "192  [associating, donald, trump, administrations, ...  \n",
       "193  [montreal, quebec, doesnt, plan, create, speci...  \n",
       "194  [community, members, treated, special, offers,...  \n",
       "195  [new, democratic, party, promising, raise, bil...  \n",
       "196  [israeli, strikes, gaza, killed, people, past,...  \n",
       "\n",
       "[197 rows x 7 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b7ea8b-1619-43b6-9e12-5ab5b60e0a24",
   "metadata": {},
   "source": [
    "# Lemmatization\n",
    "\n",
    "**Lematizasyon**, kelimeleri morfolojik paradigmalara dayanarak onların temel (lemma) formuna indirger.\n",
    "\n",
    "| Kelime   | Stemming | Lematization |\n",
    "|----------|----------|--------------|\n",
    "| playing  | play     | play         |\n",
    "| studies  | studi    | study        |\n",
    "| better   | better   | good         |\n",
    "| geese    | gees     | goose        |\n",
    "| caring   | care     | care         |\n",
    "\n",
    "> **Morfolojik Paradigma** örneği  \n",
    "> \n",
    "> “run” fiilinin paradigması şu çekimli formlardan oluşur:  \n",
    "> ```\n",
    "> run, runs, running, ran\n",
    "> ```\n",
    "> Tüm bu formlar, ortak kök “run” etrafında birçoktan-bire eşleme ile tek bir lemma’ya indirgenir:\n",
    "\n",
    "$$\n",
    "\\forall w \\in \\{\\text{run, runs, running, ran}\\},\\quad \\lambda(w) = \\text{run}\n",
    "$$\n",
    "\n",
    "Bu süreçte kelimenin:\n",
    "- **Kökü (root)**  \n",
    "- **Zamanı (tense)**  \n",
    "- **Çoğul/Hâl (plurality, case)**  \n",
    "\n",
    "gibi morfolojik bilgileri soyutlayarak yalnızca lemma formunu korur.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "831755a4-5082-4cc8-bca6-0e47f2ebb031",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/seherova/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/seherova/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/seherova/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/seherova/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ff2c35-67a1-4b1c-b704-771ced9c70d2",
   "metadata": {},
   "source": [
    "\n",
    "punkt ile cümleyi tokenize ediyorsun ➔ \"The cats are running.\" ➔ [\"The\", \"cats\", \"are\", \"running\"]\n",
    "\n",
    "averaged_perceptron_tagger ile POS tag yapıyorsun ➔ \"cats\" → NNS (çoğul isim), \"running\" → VBG (gerund verb)\n",
    "\n",
    "wordnet ile doğru lemma çekiyorsun ➔ \"cats\" ➔ \"cat\", \"running\" ➔ \"run\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd951fb8-5039-49cf-8eb9-1df40ea492ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# POS tagger için yardımcı fonksiyon\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADJ\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def lemmatize_tokens(tokens):\n",
    "    # Ensure tokens are strings\n",
    "    if isinstance(tokens, list):\n",
    "        # Filter out non-string values (e.g., floats)\n",
    "        tokens = [str(token) for token in tokens if isinstance(token, str)]\n",
    "        \n",
    "        # Apply POS tagging\n",
    "        tagged = pos_tag(tokens)\n",
    "        return [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in tagged]\n",
    "    return [] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69adaeec-1639-4a9b-93e0-efea4737cec6",
   "metadata": {},
   "source": [
    "```python from nltk.corpus import wordnet ```\n",
    "Lemmatization yaparken kelimelerin gerçek köklerini bulmak için WordNet veritabanına erişiyoruz. Yani \"running\" diye bir kelimeyi \"run\" formuna çevirirken WordNet'teki ilişkilere bakıyoruz.\n",
    "\n",
    "```python from nltk.tokenize import word_tokenize ```\n",
    "Lemmatization kelime kelime çalışır. O yüzden önce cümleyi kelimelere (tokens) bölmemiz gerekiyor.\n",
    "\n",
    "```python from nltk.tag import pos_tag```\n",
    "Lemmatizer doğru çalışabilsin diye her kelimenin türünü (isim mi, fiil mi, sıfat mı?) bilmemiz lazım. POS tagging bu iş için şart.\n",
    "\n",
    "```python from nltk.stem import WordNetLemmatizer ```python\n",
    "WordNetLemmatizer sınıfı, kelimenin kök formuna (lemma'ya) ulaşmamızı sağlar. Asıl kelimeyi değiştiren araç budur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa827426-e313-4aee-bad1-48448676cefd",
   "metadata": {},
   "source": [
    "NLTK’nin pos_tag fonksiyonu farklı bir etiket seti (Treebank) kullanır, oysa WordNetLemmatizer şunları bekler: ***wordnet.NOUN, wordnet.VERB, wordnet.ADJ, wordnet.ADV.*** Bu yüzden her Treebank etiketini WordNet formatına eşlemek gerekir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c2b114f4-58c3-4c79-81b0-2c2d71decc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_lemmatized'] = df['title_tokens'].apply(lemmatize_tokens)\n",
    "df['description_lemmatized'] = df['description_tokens'].apply(lemmatize_tokens)\n",
    "df['content_lemmatized'] = df['content_tokens'].apply(lemmatize_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8eeac244-6325-49e2-b1c6-cfb640886c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "      <th>title_tokens</th>\n",
       "      <th>description_tokens</th>\n",
       "      <th>content_tokens</th>\n",
       "      <th>title_lemmatized</th>\n",
       "      <th>description_lemmatized</th>\n",
       "      <th>content_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the tech you need to level up your humanity</td>\n",
       "      <td>advancements in computing and robotics are cha...</td>\n",
       "      <td>motion capture technology tracks movements in ...</td>\n",
       "      <td>technical</td>\n",
       "      <td>[tech, need, level, humanity]</td>\n",
       "      <td>[advancements, computing, robotics, changing, ...</td>\n",
       "      <td>[motion, capture, technology, tracks, movement...</td>\n",
       "      <td>[tech, need, level, humanity]</td>\n",
       "      <td>[advancement, compute, robotics, change, peopl...</td>\n",
       "      <td>[motion, capture, technology, track, movement,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how software engineers actually use ai</td>\n",
       "      <td>we surveyed  coders and developers about how a...</td>\n",
       "      <td>almost every coder we surveyed had strong opin...</td>\n",
       "      <td>technical</td>\n",
       "      <td>[software, engineers, actually, use, ai]</td>\n",
       "      <td>[surveyed, coders, developers, often, use, ai,...</td>\n",
       "      <td>[almost, every, coder, surveyed, strong, opini...</td>\n",
       "      <td>[software, engineer, actually, use, ai]</td>\n",
       "      <td>[survey, coder, developer, often, use, ai, cha...</td>\n",
       "      <td>[almost, every, coder, survey, strong, opinion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazons agi lab reveals its first work advance...</td>\n",
       "      <td>led by a former openai executive amazons ai la...</td>\n",
       "      <td>amazon is still seen as a bit of a laggard in ...</td>\n",
       "      <td>technical</td>\n",
       "      <td>[amazons, agi, lab, reveals, first, work, adva...</td>\n",
       "      <td>[led, former, openai, executive, amazons, ai, ...</td>\n",
       "      <td>[amazon, still, seen, bit, laggard, race, deve...</td>\n",
       "      <td>[amazon, agi, lab, reveals, first, work, advan...</td>\n",
       "      <td>[lead, former, openai, executive, amazon, ai, ...</td>\n",
       "      <td>[amazon, still, see, bit, laggard, race, devel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how microsoft made it through  years</td>\n",
       "      <td>in  microsoftâs leaders were starting to get w...</td>\n",
       "      <td>how microsoft made it through  years\\r\\nthe mo...</td>\n",
       "      <td>technical</td>\n",
       "      <td>[microsoft, made, years]</td>\n",
       "      <td>[microsoftâs, leaders, starting, get, worried,...</td>\n",
       "      <td>[microsoft, made, years, model, built, bill, g...</td>\n",
       "      <td>[microsoft, made, year]</td>\n",
       "      <td>[microsoftâs, leader, start, get, worried, win...</td>\n",
       "      <td>[microsoft, make, year, model, build, bill, ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>logistics giant gxo is going big on humanoid r...</td>\n",
       "      <td>gxo is testing humanoid robots from agility ro...</td>\n",
       "      <td>agility robotics digit robot carries totes in ...</td>\n",
       "      <td>technical</td>\n",
       "      <td>[logistics, giant, gxo, going, big, humanoid, ...</td>\n",
       "      <td>[gxo, testing, humanoid, robots, agility, robo...</td>\n",
       "      <td>[agility, robotics, digit, robot, carries, tot...</td>\n",
       "      <td>[logistics, giant, gxo, go, big, humanoid, robot]</td>\n",
       "      <td>[gxo, test, humanoid, robot, agility, robotics...</td>\n",
       "      <td>[agility, robotics, digit, robot, carry, tote,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>musk and ai among biggest threats to brand rep...</td>\n",
       "      <td>appraisal of international public affairs lead...</td>\n",
       "      <td>associating with the donald trump administrati...</td>\n",
       "      <td>technical</td>\n",
       "      <td>[musk, ai, among, biggest, threats, brand, rep...</td>\n",
       "      <td>[appraisal, international, public, affairs, le...</td>\n",
       "      <td>[associating, donald, trump, administrations, ...</td>\n",
       "      <td>[musk, ai, among, biggest, threat, brand, repu...</td>\n",
       "      <td>[appraisal, international, public, affair, lea...</td>\n",
       "      <td>[associate, donald, trump, administration, mul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>quebec says no special recruitment measures to...</td>\n",
       "      <td>montreal  quebec doesnt plan to create any spe...</td>\n",
       "      <td>montreal  quebec doesnt plan to create any spe...</td>\n",
       "      <td>medicine</td>\n",
       "      <td>[quebec, says, special, recruitment, measures,...</td>\n",
       "      <td>[montreal, quebec, doesnt, plan, create, speci...</td>\n",
       "      <td>[montreal, quebec, doesnt, plan, create, speci...</td>\n",
       "      <td>[quebec, say, special, recruitment, measure, a...</td>\n",
       "      <td>[montreal, quebec, doesnt, plan, create, speci...</td>\n",
       "      <td>[montreal, quebec, doesnt, plan, create, speci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>boy  dies after woman sends poisoned easter eg...</td>\n",
       "      <td>the childs mother and yearold sister are fight...</td>\n",
       "      <td>our community members are treated to special o...</td>\n",
       "      <td>medicine</td>\n",
       "      <td>[boy, dies, woman, sends, poisoned, easter, eg...</td>\n",
       "      <td>[childs, mother, yearold, sister, fighting, li...</td>\n",
       "      <td>[community, members, treated, special, offers,...</td>\n",
       "      <td>[boy, die, woman, sends, poison, easter, egg, ...</td>\n",
       "      <td>[child, mother, yearold, sister, fight, life, ...</td>\n",
       "      <td>[community, member, treat, special, offer, pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>ndp wealth tax would raise b pay for worker ta...</td>\n",
       "      <td>the party released its platform saturday pledg...</td>\n",
       "      <td>the new democratic party is promising to raise...</td>\n",
       "      <td>medicine</td>\n",
       "      <td>[ndp, wealth, tax, would, raise, b, pay, worke...</td>\n",
       "      <td>[party, released, platform, saturday, pledging...</td>\n",
       "      <td>[new, democratic, party, promising, raise, bil...</td>\n",
       "      <td>[ndp, wealth, tax, would, raise, b, pay, worke...</td>\n",
       "      <td>[party, release, platform, saturday, pledge, t...</td>\n",
       "      <td>[new, democratic, party, promise, raise, billi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>israeli strikes on gaza kill more than  people...</td>\n",
       "      <td>the dead include women and children sheltering...</td>\n",
       "      <td>israeli strikes in gaza have killed more than ...</td>\n",
       "      <td>medicine</td>\n",
       "      <td>[israeli, strikes, gaza, kill, people, hours, ...</td>\n",
       "      <td>[dead, include, women, children, sheltering, d...</td>\n",
       "      <td>[israeli, strikes, gaza, killed, people, past,...</td>\n",
       "      <td>[israeli, strike, gaza, kill, people, hour, sa...</td>\n",
       "      <td>[dead, include, woman, child, shelter, designa...</td>\n",
       "      <td>[israeli, strike, gaza, kill, people, past, ho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0          the tech you need to level up your humanity   \n",
       "1               how software engineers actually use ai   \n",
       "2    amazons agi lab reveals its first work advance...   \n",
       "3                 how microsoft made it through  years   \n",
       "4    logistics giant gxo is going big on humanoid r...   \n",
       "..                                                 ...   \n",
       "192  musk and ai among biggest threats to brand rep...   \n",
       "193  quebec says no special recruitment measures to...   \n",
       "194  boy  dies after woman sends poisoned easter eg...   \n",
       "195  ndp wealth tax would raise b pay for worker ta...   \n",
       "196  israeli strikes on gaza kill more than  people...   \n",
       "\n",
       "                                           description  \\\n",
       "0    advancements in computing and robotics are cha...   \n",
       "1    we surveyed  coders and developers about how a...   \n",
       "2    led by a former openai executive amazons ai la...   \n",
       "3    in  microsoftâs leaders were starting to get w...   \n",
       "4    gxo is testing humanoid robots from agility ro...   \n",
       "..                                                 ...   \n",
       "192  appraisal of international public affairs lead...   \n",
       "193  montreal  quebec doesnt plan to create any spe...   \n",
       "194  the childs mother and yearold sister are fight...   \n",
       "195  the party released its platform saturday pledg...   \n",
       "196  the dead include women and children sheltering...   \n",
       "\n",
       "                                               content   category  \\\n",
       "0    motion capture technology tracks movements in ...  technical   \n",
       "1    almost every coder we surveyed had strong opin...  technical   \n",
       "2    amazon is still seen as a bit of a laggard in ...  technical   \n",
       "3    how microsoft made it through  years\\r\\nthe mo...  technical   \n",
       "4    agility robotics digit robot carries totes in ...  technical   \n",
       "..                                                 ...        ...   \n",
       "192  associating with the donald trump administrati...  technical   \n",
       "193  montreal  quebec doesnt plan to create any spe...   medicine   \n",
       "194  our community members are treated to special o...   medicine   \n",
       "195  the new democratic party is promising to raise...   medicine   \n",
       "196  israeli strikes in gaza have killed more than ...   medicine   \n",
       "\n",
       "                                          title_tokens  \\\n",
       "0                        [tech, need, level, humanity]   \n",
       "1             [software, engineers, actually, use, ai]   \n",
       "2    [amazons, agi, lab, reveals, first, work, adva...   \n",
       "3                             [microsoft, made, years]   \n",
       "4    [logistics, giant, gxo, going, big, humanoid, ...   \n",
       "..                                                 ...   \n",
       "192  [musk, ai, among, biggest, threats, brand, rep...   \n",
       "193  [quebec, says, special, recruitment, measures,...   \n",
       "194  [boy, dies, woman, sends, poisoned, easter, eg...   \n",
       "195  [ndp, wealth, tax, would, raise, b, pay, worke...   \n",
       "196  [israeli, strikes, gaza, kill, people, hours, ...   \n",
       "\n",
       "                                    description_tokens  \\\n",
       "0    [advancements, computing, robotics, changing, ...   \n",
       "1    [surveyed, coders, developers, often, use, ai,...   \n",
       "2    [led, former, openai, executive, amazons, ai, ...   \n",
       "3    [microsoftâs, leaders, starting, get, worried,...   \n",
       "4    [gxo, testing, humanoid, robots, agility, robo...   \n",
       "..                                                 ...   \n",
       "192  [appraisal, international, public, affairs, le...   \n",
       "193  [montreal, quebec, doesnt, plan, create, speci...   \n",
       "194  [childs, mother, yearold, sister, fighting, li...   \n",
       "195  [party, released, platform, saturday, pledging...   \n",
       "196  [dead, include, women, children, sheltering, d...   \n",
       "\n",
       "                                        content_tokens  \\\n",
       "0    [motion, capture, technology, tracks, movement...   \n",
       "1    [almost, every, coder, surveyed, strong, opini...   \n",
       "2    [amazon, still, seen, bit, laggard, race, deve...   \n",
       "3    [microsoft, made, years, model, built, bill, g...   \n",
       "4    [agility, robotics, digit, robot, carries, tot...   \n",
       "..                                                 ...   \n",
       "192  [associating, donald, trump, administrations, ...   \n",
       "193  [montreal, quebec, doesnt, plan, create, speci...   \n",
       "194  [community, members, treated, special, offers,...   \n",
       "195  [new, democratic, party, promising, raise, bil...   \n",
       "196  [israeli, strikes, gaza, killed, people, past,...   \n",
       "\n",
       "                                      title_lemmatized  \\\n",
       "0                        [tech, need, level, humanity]   \n",
       "1              [software, engineer, actually, use, ai]   \n",
       "2    [amazon, agi, lab, reveals, first, work, advan...   \n",
       "3                              [microsoft, made, year]   \n",
       "4    [logistics, giant, gxo, go, big, humanoid, robot]   \n",
       "..                                                 ...   \n",
       "192  [musk, ai, among, biggest, threat, brand, repu...   \n",
       "193  [quebec, say, special, recruitment, measure, a...   \n",
       "194  [boy, die, woman, sends, poison, easter, egg, ...   \n",
       "195  [ndp, wealth, tax, would, raise, b, pay, worke...   \n",
       "196  [israeli, strike, gaza, kill, people, hour, sa...   \n",
       "\n",
       "                                description_lemmatized  \\\n",
       "0    [advancement, compute, robotics, change, peopl...   \n",
       "1    [survey, coder, developer, often, use, ai, cha...   \n",
       "2    [lead, former, openai, executive, amazon, ai, ...   \n",
       "3    [microsoftâs, leader, start, get, worried, win...   \n",
       "4    [gxo, test, humanoid, robot, agility, robotics...   \n",
       "..                                                 ...   \n",
       "192  [appraisal, international, public, affair, lea...   \n",
       "193  [montreal, quebec, doesnt, plan, create, speci...   \n",
       "194  [child, mother, yearold, sister, fight, life, ...   \n",
       "195  [party, release, platform, saturday, pledge, t...   \n",
       "196  [dead, include, woman, child, shelter, designa...   \n",
       "\n",
       "                                    content_lemmatized  \n",
       "0    [motion, capture, technology, track, movement,...  \n",
       "1    [almost, every, coder, survey, strong, opinion...  \n",
       "2    [amazon, still, see, bit, laggard, race, devel...  \n",
       "3    [microsoft, make, year, model, build, bill, ga...  \n",
       "4    [agility, robotics, digit, robot, carry, tote,...  \n",
       "..                                                 ...  \n",
       "192  [associate, donald, trump, administration, mul...  \n",
       "193  [montreal, quebec, doesnt, plan, create, speci...  \n",
       "194  [community, member, treat, special, offer, pro...  \n",
       "195  [new, democratic, party, promise, raise, billi...  \n",
       "196  [israeli, strike, gaza, kill, people, past, ho...  \n",
       "\n",
       "[197 rows x 10 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf04ea9-83c3-4054-8f5f-ff5b0b5e4adb",
   "metadata": {},
   "source": [
    "# Bag Of Words (BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3d833f91-6fd0-44ac-89bf-f1b9bb74e505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4d6f1328-b5d2-42a9-95f2-f94c069567e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Users/seherova/.pyenv/versions/3.10.12/lib/python3.10/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/seherova/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/seherova/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from scikit-learn) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/seherova/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/seherova/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9bb39e32-0a77-4439-b4c1-a1635159ade7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/seherova/.pyenv/versions/3.10.12/lib/python3.10/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /Users/seherova/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/seherova/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/seherova/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /Users/seherova/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from nltk) (4.64.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8ada5bc3-3dc6-49de-8356-a4eff0f5d016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "42ac33b7-7a15-4a55-a58f-ff6826550fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "      <th>title_tokens</th>\n",
       "      <th>description_tokens</th>\n",
       "      <th>content_tokens</th>\n",
       "      <th>title_lemmatized</th>\n",
       "      <th>description_lemmatized</th>\n",
       "      <th>content_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the tech you need to level up your humanity</td>\n",
       "      <td>advancements in computing and robotics are cha...</td>\n",
       "      <td>motion capture technology tracks movements in ...</td>\n",
       "      <td>technical</td>\n",
       "      <td>[tech, need, level, humanity]</td>\n",
       "      <td>[advancements, computing, robotics, changing, ...</td>\n",
       "      <td>[motion, capture, technology, tracks, movement...</td>\n",
       "      <td>[tech, need, level, humanity]</td>\n",
       "      <td>[advancement, compute, robotics, change, peopl...</td>\n",
       "      <td>[motion, capture, technology, track, movement,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how software engineers actually use ai</td>\n",
       "      <td>we surveyed  coders and developers about how a...</td>\n",
       "      <td>almost every coder we surveyed had strong opin...</td>\n",
       "      <td>technical</td>\n",
       "      <td>[software, engineers, actually, use, ai]</td>\n",
       "      <td>[surveyed, coders, developers, often, use, ai,...</td>\n",
       "      <td>[almost, every, coder, surveyed, strong, opini...</td>\n",
       "      <td>[software, engineer, actually, use, ai]</td>\n",
       "      <td>[survey, coder, developer, often, use, ai, cha...</td>\n",
       "      <td>[almost, every, coder, survey, strong, opinion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazons agi lab reveals its first work advance...</td>\n",
       "      <td>led by a former openai executive amazons ai la...</td>\n",
       "      <td>amazon is still seen as a bit of a laggard in ...</td>\n",
       "      <td>technical</td>\n",
       "      <td>[amazons, agi, lab, reveals, first, work, adva...</td>\n",
       "      <td>[led, former, openai, executive, amazons, ai, ...</td>\n",
       "      <td>[amazon, still, seen, bit, laggard, race, deve...</td>\n",
       "      <td>[amazon, agi, lab, reveals, first, work, advan...</td>\n",
       "      <td>[lead, former, openai, executive, amazon, ai, ...</td>\n",
       "      <td>[amazon, still, see, bit, laggard, race, devel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how microsoft made it through  years</td>\n",
       "      <td>in  microsoftâs leaders were starting to get w...</td>\n",
       "      <td>how microsoft made it through  years\\r\\nthe mo...</td>\n",
       "      <td>technical</td>\n",
       "      <td>[microsoft, made, years]</td>\n",
       "      <td>[microsoftâs, leaders, starting, get, worried,...</td>\n",
       "      <td>[microsoft, made, years, model, built, bill, g...</td>\n",
       "      <td>[microsoft, made, year]</td>\n",
       "      <td>[microsoftâs, leader, start, get, worried, win...</td>\n",
       "      <td>[microsoft, make, year, model, build, bill, ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>logistics giant gxo is going big on humanoid r...</td>\n",
       "      <td>gxo is testing humanoid robots from agility ro...</td>\n",
       "      <td>agility robotics digit robot carries totes in ...</td>\n",
       "      <td>technical</td>\n",
       "      <td>[logistics, giant, gxo, going, big, humanoid, ...</td>\n",
       "      <td>[gxo, testing, humanoid, robots, agility, robo...</td>\n",
       "      <td>[agility, robotics, digit, robot, carries, tot...</td>\n",
       "      <td>[logistics, giant, gxo, go, big, humanoid, robot]</td>\n",
       "      <td>[gxo, test, humanoid, robot, agility, robotics...</td>\n",
       "      <td>[agility, robotics, digit, robot, carry, tote,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0        the tech you need to level up your humanity   \n",
       "1             how software engineers actually use ai   \n",
       "2  amazons agi lab reveals its first work advance...   \n",
       "3               how microsoft made it through  years   \n",
       "4  logistics giant gxo is going big on humanoid r...   \n",
       "\n",
       "                                         description  \\\n",
       "0  advancements in computing and robotics are cha...   \n",
       "1  we surveyed  coders and developers about how a...   \n",
       "2  led by a former openai executive amazons ai la...   \n",
       "3  in  microsoftâs leaders were starting to get w...   \n",
       "4  gxo is testing humanoid robots from agility ro...   \n",
       "\n",
       "                                             content   category  \\\n",
       "0  motion capture technology tracks movements in ...  technical   \n",
       "1  almost every coder we surveyed had strong opin...  technical   \n",
       "2  amazon is still seen as a bit of a laggard in ...  technical   \n",
       "3  how microsoft made it through  years\\r\\nthe mo...  technical   \n",
       "4  agility robotics digit robot carries totes in ...  technical   \n",
       "\n",
       "                                        title_tokens  \\\n",
       "0                      [tech, need, level, humanity]   \n",
       "1           [software, engineers, actually, use, ai]   \n",
       "2  [amazons, agi, lab, reveals, first, work, adva...   \n",
       "3                           [microsoft, made, years]   \n",
       "4  [logistics, giant, gxo, going, big, humanoid, ...   \n",
       "\n",
       "                                  description_tokens  \\\n",
       "0  [advancements, computing, robotics, changing, ...   \n",
       "1  [surveyed, coders, developers, often, use, ai,...   \n",
       "2  [led, former, openai, executive, amazons, ai, ...   \n",
       "3  [microsoftâs, leaders, starting, get, worried,...   \n",
       "4  [gxo, testing, humanoid, robots, agility, robo...   \n",
       "\n",
       "                                      content_tokens  \\\n",
       "0  [motion, capture, technology, tracks, movement...   \n",
       "1  [almost, every, coder, surveyed, strong, opini...   \n",
       "2  [amazon, still, seen, bit, laggard, race, deve...   \n",
       "3  [microsoft, made, years, model, built, bill, g...   \n",
       "4  [agility, robotics, digit, robot, carries, tot...   \n",
       "\n",
       "                                    title_lemmatized  \\\n",
       "0                      [tech, need, level, humanity]   \n",
       "1            [software, engineer, actually, use, ai]   \n",
       "2  [amazon, agi, lab, reveals, first, work, advan...   \n",
       "3                            [microsoft, made, year]   \n",
       "4  [logistics, giant, gxo, go, big, humanoid, robot]   \n",
       "\n",
       "                              description_lemmatized  \\\n",
       "0  [advancement, compute, robotics, change, peopl...   \n",
       "1  [survey, coder, developer, often, use, ai, cha...   \n",
       "2  [lead, former, openai, executive, amazon, ai, ...   \n",
       "3  [microsoftâs, leader, start, get, worried, win...   \n",
       "4  [gxo, test, humanoid, robot, agility, robotics...   \n",
       "\n",
       "                                  content_lemmatized  \n",
       "0  [motion, capture, technology, track, movement,...  \n",
       "1  [almost, every, coder, survey, strong, opinion...  \n",
       "2  [amazon, still, see, bit, laggard, race, devel...  \n",
       "3  [microsoft, make, year, model, build, bill, ga...  \n",
       "4  [agility, robotics, digit, robot, carry, tote,...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "552d641c-493a-4605-9147-6dfbdba5f002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   title_abest  title_ability  title_absolute  title_absolutely  \\\n",
      "0            0              0               0                 0   \n",
      "1            0              0               0                 0   \n",
      "2            0              0               0                 0   \n",
      "3            0              0               0                 0   \n",
      "4            0              0               0                 0   \n",
      "\n",
      "   title_absurdly  title_abuse  title_accelerate  title_access  \\\n",
      "0               0            0                 0             0   \n",
      "1               0            0                 0             0   \n",
      "2               0            0                 0             0   \n",
      "3               0            0                 0             0   \n",
      "4               0            0                 0             0   \n",
      "\n",
      "   title_accident  title_accord  ...  content_yell  content_yet  content_york  \\\n",
      "0               0             0  ...             0            0             0   \n",
      "1               0             0  ...             0            0             0   \n",
      "2               0             0  ...             0            0             0   \n",
      "3               0             0  ...             0            0             0   \n",
      "4               0             0  ...             0            0             0   \n",
      "\n",
      "   content_young  content_youre  content_youtube  content_youtuber  \\\n",
      "0              0              0                0                 0   \n",
      "1              0              0                0                 0   \n",
      "2              0              0                0                 0   \n",
      "3              0              0                0                 0   \n",
      "4              0              0                0                 0   \n",
      "\n",
      "   content_youve  content_zers  content_zone  \n",
      "0              0             0             0  \n",
      "1              0             0             0  \n",
      "2              0             0             0  \n",
      "3              0             0             0  \n",
      "4              0             0             0  \n",
      "\n",
      "[5 rows x 6087 columns]\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "from scipy.sparse import hstack\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "df['title_bow_corpus'] = df['title_lemmatized'].apply(lambda toks: ' '.join(toks))\n",
    "df['description_bow_corpus'] = df['description_lemmatized'].apply(lambda toks: ' '.join(toks))\n",
    "df['content_bow_corpus'] = df['description_lemmatized'].apply(lambda toks: ' '.join(toks))\n",
    "\n",
    "\n",
    "def remove_diacritics(text):\n",
    "    nfkd = unicodedata.normalize('NFKD', text)\n",
    "    return ''.join(c for c in nfkd if not unicodedata.combining(c))\n",
    "\n",
    "for col in ['title_bow_corpus', 'description_bow_corpus', 'content_bow_corpus']:\n",
    "    df[col] = df[col].apply(remove_diacritics)\n",
    "\n",
    "all_corpara = pd.concat(\n",
    "    [\n",
    "        df['title_bow_corpus'],\n",
    "        df['description_bow_corpus'],\n",
    "        df['content_bow_corpus']\n",
    "    ]\n",
    ")\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(all_corpara)\n",
    "\n",
    "title_bow_matrix = vectorizer.transform(df['title_bow_corpus'])\n",
    "description_bow_matrix = vectorizer.transform(df['description_bow_corpus'])\n",
    "content_bow_matrix = vectorizer.transform(df['content_bow_corpus'])\n",
    "\n",
    "#hepsini yatayda birleştirip dataframe'e dönüştüreceğiz\n",
    "X_combined = hstack([title_bow_matrix, description_bow_matrix, content_bow_matrix])\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "columns = (\n",
    "    ['title_' + w for w in feature_names] +\n",
    "    ['desc_' + w for w in feature_names] +\n",
    "    ['content_' + w for w in feature_names]\n",
    ")\n",
    "\n",
    "bow_df = pd.DataFrame.sparse.from_spmatrix(X_combined, columns=columns)\n",
    "\n",
    "print(bow_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce52cdb8-c7e4-4334-b236-444201339ccb",
   "metadata": {},
   "source": [
    "vectorizer: Bu, CountVectorizer gibi metin dönüştürücüleri temsil eder ve veriyi sayısal vektörlere dönüştürmeden önce metni analiz eder. Bu analiz sonucunda kelime hazinesi (vocabulary) oluşturur. Yani metindeki kelimeleri (özellikleri) tanımlar.\n",
    "\n",
    "get_feature_names_out(): Bu fonksiyon, CountVectorizer tarafından oluşturulan kelime hazinesindeki tüm kelimelerin adlarını döndürür. Sonuç olarak, metninize ait kelimelerle ilişkili olan özelliklerin (features) adlarını alırsınız.\n",
    "\n",
    "\n",
    "Metin verisini sayısal verilere dönüştürürken, her bir kelime (veya n-gram) bir özellik (feature) olarak kabul edilir. Bu özellik adları, CountVectorizer'ın kelime hazinesindeki tüm kelimeleri temsil eder. get_feature_names_out() fonksiyonu, bu kelimeleri (özellikleri) alır ve size döndürür.\n",
    "\n",
    "Kullanım Alanı:\n",
    "Metin analizi veya doğal dil işleme (NLP) uygulamalarında, metni sayısal verilere dönüştürdüğünüzde, her kelimenin bir sütun (özellik) haline geldiği bir matris elde edersiniz. Bu özelliklerin hangi kelimelere karşılık geldiğini görmek için get_feature_names_out() fonksiyonunu kullanırsınız.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "19443997-b967-48b6-bb39-a7b3e654e881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shared vocab size: 2029\n",
      "Title BoW shape:       (197, 2029)\n",
      "Description BoW shape: (197, 2029)\n",
      "Content BoW shape:     (197, 2029)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Shared vocab size:\", len(vectorizer.vocabulary_))\n",
    "print(\"Title BoW shape:      \", title_bow_matrix.shape)\n",
    "print(\"Description BoW shape:\", description_bow_matrix.shape)\n",
    "print(\"Content BoW shape:    \", content_bow_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56195fa2-deed-4f2c-b3d5-38f1467a2c3e",
   "metadata": {},
   "source": [
    "# TF-IDF (Term Frequency - Inverse Document Frequency) Nedir?\n",
    "\n",
    "**TF-IDF** (Term Frequency-Inverse Document Frequency), metin madenciliği ve doğal dil işleme (NLP) alanında kullanılan bir ağırlıklandırma yöntemidir. Bu yöntem, bir terimin bir belgeyi ne kadar iyi temsil ettiğini ölçmeye yardımcı olur ve çok sık geçen ama anlam taşımayan kelimelerin (örneğin, \"ve\", \"the\", \"is\") ağırlığını azaltırken, belgedeki önemli terimleri daha fazla vurgular.\n",
    "\n",
    "---\n",
    "\n",
    "### TF-IDF İki Temel Kavramdan Oluşur:\n",
    "1. **TF (Term Frequency)**: Terim Frekansı\n",
    "2. **IDF (Inverse Document Frequency)**: Ters Belge Frekansı\n",
    "\n",
    "---\n",
    "\n",
    "## 1. **TF (Term Frequency)**: Terim Frekansı\n",
    "\n",
    "Terim frekansı, bir terimin (kelimenin) belirli bir belgede **ne kadar sık geçtiğini** gösterir. Genellikle şu şekilde hesaplanır:\n",
    "\n",
    "\\[\n",
    "\\text{TF}(t,d) = \\frac{\\text{Belgedeki Terim Sayısı (t)}}{\\text{Belgedeki Toplam Terim Sayısı}}\n",
    "\\]\n",
    "\n",
    "- **t**: Terim (kelime)\n",
    "- **d**: Belge\n",
    "\n",
    "Yani, bir terimin frekansı, o terimin belge içindeki tekrar sayısının, belge içindeki toplam kelime sayısına bölünmesidir. Bu, bir kelimenin belgede ne kadar yoğun bir şekilde geçtiğini ölçer.\n",
    "\n",
    "**Örnek:**\n",
    "Bir belgeyi düşünün: `\"the cat sat on the mat\"`. Burada `\"the\"` kelimesi 2 kez geçiyor ve toplamda 6 kelime var, bu yüzden `TF(the)`:\n",
    "\n",
    "\\[\n",
    "\\text{TF(the)} = \\frac{2}{6} = 0.33\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "## 2. **IDF (Inverse Document Frequency)**: Ters Belge Frekansı\n",
    "\n",
    "IDF, bir terimin **belgelerde ne kadar yaygın olduğunu** ölçer. Yüksek IDF değeri, terimin daha az belgede geçtiği anlamına gelir. Bu da o terimin o belge için daha **önemli** olduğunu gösterir.\n",
    "\n",
    "IDF, aşağıdaki formülle hesaplanır:\n",
    "\n",
    "\\[\n",
    "\\text{IDF}(t) = \\log \\left( \\frac{N}{1 + df(t)} \\right)\n",
    "\\]\n",
    "\n",
    "- **N**: Toplam belge sayısı\n",
    "- **df(t)**: Terim **t**'yi içeren belge sayısı\n",
    "\n",
    "IDF, daha yaygın terimler için düşük, nadiren bulunan terimler için yüksek değerler üretir. Bu sayede, çok sık geçen kelimelerin (örneğin, \"ve\", \"the\") ağırlığı düşer.\n",
    "\n",
    "**Örnek:**\n",
    "Eğer toplam 100 belge varsa ve `\"cat\"` kelimesi 10 belgede geçtiyse, IDF hesaplaması şu şekilde yapılır:\n",
    "\n",
    "\\[\n",
    "\\text{IDF(cat)} = \\log \\left( \\frac{100}{1 + 10} \\right) = \\log \\left( \\frac{100}{11} \\right) \\approx 1.95\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "## 3. **TF-IDF Hesaplaması**\n",
    "\n",
    "TF-IDF, her terim için TF ve IDF’nin çarpımıdır:\n",
    "\n",
    "\\[\n",
    "\\text{TF-IDF}(t,d) = \\text{TF}(t,d) \\times \\text{IDF}(t)\n",
    "\\]\n",
    "\n",
    "Yani, bir terimin **önemi**, o terimin belgedeki sıklığıyla (TF) ve belgelerdeki nadirliğiyle (IDF) belirlenir.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. **Örnek ve Mantık**\n",
    "\n",
    "Diyelim ki üç belge var:\n",
    "1. `\"the cat sat on the mat\"`\n",
    "2. `\"the dog sat on the log\"`\n",
    "3. `\"the bird sat on the log\"`\n",
    "\n",
    "- **TF**: Her terimi belgelerdeki sıklığıyla ölçeriz. Örneğin, `\"sat\"` terimi her belgede 1 kez geçiyor, ancak bu terim sadece bu belgelerde geçtiği için, TF değeri yüksektir.\n",
    "  \n",
    "- **IDF**: Örneğin, `\"the\"` kelimesi tüm belgelerde geçiyor, bu yüzden IDF değeri çok düşer. `\"mat\"` ise sadece 1. belgede geçiyor, bu yüzden IDF değeri yüksek olur.\n",
    "\n",
    "- **TF-IDF**: `\"sat\"` kelimesi, her belgede aynı sıklıkta geçmesine rağmen, `IDF`'si düşük olduğu için TF-IDF değeri düşük olur. `\"mat\"` kelimesi ise daha nadir olduğu için, `IDF`'si yüksek olacak ve TF-IDF değeri daha yüksek olur.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. **TF-IDF'ın Avantajları**\n",
    "- **Önemli Terimler Vurgulanır**: Çok yaygın kelimeler (stop words) otomatik olarak düşük ağırlığa sahip olur, bu da modelin daha önemli terimlere odaklanmasını sağlar.\n",
    "- **Belge Temsili**: Metinler, kelimelerin önemine göre vektörlere dönüştürülür. Bu da metinlerin makine öğrenmesi modelleri için daha iyi temsil edilmesini sağlar.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "06160c11-69ab-4347-adc8-9d31c7bc2a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "\n",
    "title_tfidf = tfidf_vectorizer.fit_transform(df['title_lemmatized'].apply(lambda x: ' '.join(x) if len(x) > 0 else ' '))\n",
    "desc_tfidf = tfidf_vectorizer.transform(df['description_lemmatized'].apply(lambda x: ' '.join(x) if len(x) > 0 else ' '))\n",
    "content_tfidf = tfidf_vectorizer.transform(df['content_lemmatized'].apply(lambda x: ' '.join(x) if len(x) > 0 else ' '))\n",
    "\n",
    "X_tfidf_combined = hstack([title_tfidf, desc_tfidf, content_tfidf])\n",
    "\n",
    "tfidf_df = pd.DataFrame.sparse.from_spmatrix(\n",
    "    X_tfidf_combined,\n",
    "    columns=['title_tfidf_' + col for col in tfidf_vectorizer.get_feature_names_out()] +\n",
    "            ['desc_tfidf_' + col for col in tfidf_vectorizer.get_feature_names_out()] +\n",
    "            ['content_tfidf_' + col for col in tfidf_vectorizer.get_feature_names_out()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0a6ec60d-d269-4150-ae79-ec734d32370e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   title_tfidf_access  title_tfidf_accident  title_tfidf_achieve  \\\n",
      "0                   0                     0                    0   \n",
      "1                   0                     0                    0   \n",
      "2                   0                     0                    0   \n",
      "3                   0                     0                    0   \n",
      "4                   0                     0                    0   \n",
      "\n",
      "   title_tfidf_act  title_tfidf_actually  title_tfidf_ad  title_tfidf_add  \\\n",
      "0                0                     0               0                0   \n",
      "1                0              0.560003               0                0   \n",
      "2                0                     0               0                0   \n",
      "3                0                     0               0                0   \n",
      "4                0                     0               0                0   \n",
      "\n",
      "   title_tfidf_addition  title_tfidf_admin  title_tfidf_administration  ...  \\\n",
      "0                     0                  0                           0  ...   \n",
      "1                     0                  0                           0  ...   \n",
      "2                     0                  0                           0  ...   \n",
      "3                     0                  0                           0  ...   \n",
      "4                     0                  0                           0  ...   \n",
      "\n",
      "   content_tfidf_write  content_tfidf_wrong  content_tfidf_yahoo  \\\n",
      "0                    0                    0                    0   \n",
      "1                    0                    0                    0   \n",
      "2                    0                    0                    0   \n",
      "3                    0                    0                    0   \n",
      "4                    0                    0                    0   \n",
      "\n",
      "   content_tfidf_year  content_tfidf_yearold  content_tfidf_yet  \\\n",
      "0                   0                      0                  0   \n",
      "1                   0                      0                  0   \n",
      "2                   0                      0                  0   \n",
      "3            0.427523                      0                  0   \n",
      "4                   0                      0                  0   \n",
      "\n",
      "   content_tfidf_youre  content_tfidf_youtube  content_tfidf_youtuber  \\\n",
      "0                    0                      0                       0   \n",
      "1                    0                      0                       0   \n",
      "2                    0                      0                       0   \n",
      "3                    0                      0                       0   \n",
      "4                    0                      0                       0   \n",
      "\n",
      "   content_tfidf_zers  \n",
      "0                   0  \n",
      "1                   0  \n",
      "2                   0  \n",
      "3                   0  \n",
      "4                   0  \n",
      "\n",
      "[5 rows x 2907 columns]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b6d5a2e4-8c92-4979-bf08-29ad136184e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = df[\"category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bed9e2fc-c67b-4472-b1d0-306bfac72d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def train_and_evaluate(X, y, model_name=\"SVM\"):\n",
    "    results = {}\n",
    "\n",
    "    # X ve y uyumlu olsun\n",
    "    X = X.reset_index(drop=True)\n",
    "    y = y.reset_index(drop=True)\n",
    "\n",
    "    # Eğitim ve test bölme\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Model seçimi\n",
    "    if model_name == \"SVM\":\n",
    "        model = SVC()\n",
    "        # SVC sparse matrix kabul etmez, dense yapıyoruz\n",
    "        X_train = X_train.to_numpy()\n",
    "        X_test = X_test.to_numpy()\n",
    "    elif model_name == \"NaiveBayes\":\n",
    "        model = MultinomialNB()\n",
    "    else:\n",
    "        raise ValueError(\"Model adı sadece 'SVM' veya 'NaiveBayes' olmalı!\")\n",
    "\n",
    "    # Eğit ve tahmin yap\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Performans skorları\n",
    "    results[\"Accuracy\"] = accuracy_score(y_test, y_pred)\n",
    "    results[\"Precision\"] = precision_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "    results[\"Recall\"] = recall_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "    results[\"F1-Score\"] = f1_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eac88877-d59a-4af8-b7a8-68e8f8313da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = [\"SVM\", \"NaiveBayes\"]\n",
    "vectorizers = {\"BoW\": bow_df, \"TF-IDF\": tfidf_df}\n",
    "\n",
    "final_results = {}\n",
    "\n",
    "for vec_name, X in vectorizers.items():\n",
    "    final_results[vec_name] = {}\n",
    "    for model in models:\n",
    "        result = train_and_evaluate(X, y, model_name=model)\n",
    "        final_results[vec_name][model] = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "424991fc-7bfa-4c5c-b871-95ba6bbad226",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"SVM\", \"NaiveBayes\"]\n",
    "vectorizers = {\"BoW\": bow_df, \"TF-IDF\": tfidf_df}\n",
    "\n",
    "final_results = {}\n",
    "\n",
    "for vec_name, X in vectorizers.items():\n",
    "    final_results[vec_name] = {}\n",
    "    for model in models:\n",
    "        result = train_and_evaluate(X, y, model_name=model)\n",
    "        final_results[vec_name][model] = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5ac3e3d0-9ad0-411a-998b-bbe2f0a2a7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Vectorizer       Model  Accuracy  Precision  Recall  F1-Score\n",
      "0        BoW         SVM     0.850   0.852813   0.850  0.849242\n",
      "1        BoW  NaiveBayes     1.000   1.000000   1.000  1.000000\n",
      "2     TF-IDF         SVM     0.975   0.976136   0.975  0.974953\n",
      "3     TF-IDF  NaiveBayes     0.975   0.976136   0.975  0.974953\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for vec_name, models_dict in final_results.items():\n",
    "    for model_name, metrics in models_dict.items():\n",
    "        row = {\n",
    "            \"Vectorizer\": vec_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Accuracy\": metrics[\"Accuracy\"],\n",
    "            \"Precision\": metrics[\"Precision\"],\n",
    "            \"Recall\": metrics[\"Recall\"],\n",
    "            \"F1-Score\": metrics[\"F1-Score\"]\n",
    "        }\n",
    "        results_list.append(row)\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
